{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 2 - BCC406\n",
        "\n",
        "## REDES NEURAIS E APRENDIZAGEM EM PROFUNDIDADE\n",
        "\n",
        "## Regressão Logística e Rede Neural\n",
        "\n",
        "### Prof. Eduardo e Prof. Pedro\n",
        "\n",
        "Objetivos:\n",
        "\n",
        "- Regressão e Descida do Gradiente\n",
        "\n",
        "Data da entrega : 26/08 \n",
        "\n",
        "- Complete o código (marcado com ToDo) e quando requisitado, escreva textos diretamente nos notebooks. Onde tiver *None*, substitua pelo seu código.\n",
        "- Execute todo notebook e salve tudo em um PDF **nomeado** como \"NomeSobrenome-LabX.pdf\"\n",
        "- Envie o PDF via google [FORM](https://forms.gle/MWB1mHjTADbnD6kN8)\n"
      ],
      "metadata": {
        "id": "LSPMRVgVvGH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classificação utilizando frameworks"
      ],
      "metadata": {
        "id": "n-Ra_B-7wCr3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " - Trabalharemos com um problema de classificação: é um gato ou não é um gato.\n",
        " - Utilizaremos um framework: o Tensorflow/Keras."
      ],
      "metadata": {
        "id": "f91TyC6yu-WY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importando os pacotes"
      ],
      "metadata": {
        "id": "S3fSrw6Zw8l9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primeiro, vamos executar a célula abaixo para importar todos os pacotes que precisaremos.\n",
        "- [numpy](www.numpy.org) é o pacote fundamental para a computação científica com Python.\n",
        "- [h5py](http://www.h5py.org) é um pacote comum para interagir com um conjunto de dados armazenado em um arquivo H5.\n",
        "- [matplotlib](http://matplotlib.org) é uma biblioteca famosa para plotar gráficos em Python.\n",
        "- [PIL](http://www.pythonware.com/products/pil/) e [scipy](https://www.scipy.org/) são usados aqui para testar seu modelo.\n",
        "- [tensorflow](https://www.tensorflow.org/?hl=pt-br) é uma biblioteca famosa para criar e treinar modelos de Deep Learning.\n",
        "- np.random.seed (1) é usado para manter todas as chamadas de funções aleatórias. "
      ],
      "metadata": {
        "id": "fwF-za01tVqL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import Sequential\n",
        "from tensorflow.python.keras.layers import Dense\n",
        "from tensorflow.keras import initializers"
      ],
      "metadata": {
        "id": "cG9YYwCiw7Bu"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configurando o matplotlib e a geração de dados aleatórios"
      ],
      "metadata": {
        "id": "Ku-1zZNGuFVj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "np.random.seed(1)"
      ],
      "metadata": {
        "id": "DR8iUqsDuEuP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configurando o Google Colab"
      ],
      "metadata": {
        "id": "dd7u2wMHtbq3"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9BlvNrOLl3M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30814dc1-76b5-4ae8-ff53-50633b0e8eae"
      },
      "source": [
        "# Para Google Colab: Você vai precisar fazer o upload dos arquivos no seu drive e montá-lo\n",
        "# não se esqueça de ajustar o path para o seu drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carregando os dados (10pt)"
      ],
      "metadata": {
        "id": "77zwCEdJs-Hw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Coloque os arquivos *train_catvnonvat.h5* e *test_catvnoncat.h5* na pasta raiz do seu Drive. Ambos os arquivos estão na pasta dataset da pasta compartilhada."
      ],
      "metadata": {
        "id": "WNQi7eXxyMoS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lendo os dados (gato/não-gato)\n",
        "def load_dataset():\n",
        "\n",
        "  train_dataset = h5py.File('train_catvnoncat.h5', \"r\")\n",
        "  train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
        "  train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
        "\n",
        "  test_dataset = h5py.File('test_catvnoncat.h5', \"r\")\n",
        "  test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
        "  test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
        "\n",
        "  classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
        "  train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
        "  test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
        "  \n",
        "  return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes"
      ],
      "metadata": {
        "id": "drTGqC0yDUu3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lendo os dados (gato/não-gato)\n",
        "treino_x_orig, treino_y, teste_x_orig, teste_y, classes = load_dataset()"
      ],
      "metadata": {
        "id": "C34CTsOTDYs-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pré-processamento dos dados"
      ],
      "metadata": {
        "id": "zdCZTNFQukN3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-processamento necessário. Iremos converter a imagem 3D (64x64x3) em um único vetor 1D (12288 = 64x64x3). A figura mostra um exemplo do pré-processamento executado (imagem vetorizada)\n",
        "\n",
        "![Arq,widht=10](https://drive.google.com/uc?export=view&id=1zCnEB2rwc4lXU_7RTS4TXhqCwsJubg7H)\n",
        "\n",
        "<caption><center> <u>Figura</u>: Vetorização de uma imagem. <br> </center></caption>"
      ],
      "metadata": {
        "id": "RxlUbI6-DZyu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ToDo:** Vetorização da imagem (10pt)"
      ],
      "metadata": {
        "id": "blAQmRbWvQ04"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converta as imagens do formato 64x64x3 para 12288x1."
      ],
      "metadata": {
        "id": "lzg2f_xjvWnj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m_treino = len(treino_x_orig)\n",
        "m_teste = len(teste_x_orig)\n",
        "num_px = teste_x_orig[1].shape[1]\n",
        "\n",
        "\n",
        "#  Vetorizando as imagens de treinamento e teste \n",
        "\n",
        "### Início do código ###\n",
        "treino_x = treino_x_orig.reshape((m_treino, num_px*num_px*3)) # dica : utilize reshape para mudar o formato dos dados\n",
        "### Fim do código ###\n",
        "\n",
        "### Início do código ###\n",
        "# Normalize os dados para ter valores de recurso entre 0 e 1.\n",
        "teste_x = teste_x_orig.reshape((m_teste, num_px*num_px*3)) # dica : utilize reshape para mudar o formato dos dados\n",
        "### Fim do código ###"
      ],
      "metadata": {
        "id": "T0FESSiqvDTx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testando redes neurais e *sigmoid*"
      ],
      "metadata": {
        "id": "mVdVdtCsvd9n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para classificação de classes 0 ou 1, pode-se ter um único neurônio de saída e deve-se usar a operação sigmoid antes de se calcular o custo (mean-squared error ou binary cross entropy).\n"
      ],
      "metadata": {
        "id": "6Yd22nPws4nR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Testando uma rede com uma camada oculta\n",
        "\n",
        "![Arq,widht=10](https://drive.google.com/uc?export=view&id=19mux_FFpeZkj5YiV51bNE2CK3i2nBSau)\n",
        "<caption><center> <u>Figura 7</u>: Rede neural com 2 camadas. <br> Resumo do modelo: ***ENTRADA -> LINEAR -> RELU -> LINEAR -> SIGMOID -> SAIDA***. </center></caption>\n",
        "\n",
        "<!--\n",
        "<u>Detailed Architecture of figure 2</u>:\n",
        "- The input is a (64,64,3) image which is flattened to a vector of size $(12288,1)$. \n",
        "- The corresponding vector: $[x_0,x_1,...,x_{12287}]^T$ is then multiplied by the weight matrix $W^{[1]}$ of size $(n^{[1]}, 12288)$.\n",
        "- You then add a bias term and take its relu to get the following vector: $[a_0^{[1]}, a_1^{[1]},..., a_{n^{[1]}-1}^{[1]}]^T$.\n",
        "- You then repeat the same process.\n",
        "- You multiply the resulting vector by $W^{[2]}$ and add your intercept (bias). \n",
        "- Finally, you take the sigmoid of the result. If it is greater than 0.5, you classify it to be a cat.\n",
        "!-->"
      ],
      "metadata": {
        "id": "3p4myz5bEViP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Setando a seed\n",
        "np.random.seed(1)\n",
        "random.seed(1)\n",
        "\n",
        "### Executar uma rede de 1 camada oculta ###\n",
        "# Camadas da rede = [12288, 200, 1] \n",
        "\n",
        "# Definição do modelo\n",
        "model = Sequential()\n",
        "model.add(Dense(200, input_shape=(12288,), activation='relu', name='CamadaOculta'))\n",
        "model.add(Dense(1, activation='sigmoid', name='CamadaClassificacao'))\n",
        "\n",
        "# Compilando o modelo\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "\n",
        "# Imprimindo a arquitetura da rede proposta\n",
        "model.summary()\n",
        "\n",
        "# Treinando o modelo\n",
        "model.fit(treino_x, treino_y.reshape(-1), epochs=100)"
      ],
      "metadata": {
        "id": "xqP_cm7ZEYpN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5657de13-645a-43a8-9fca-19a2909a5c0c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "CamadaOculta (Dense)         (None, 200)               2457800   \n",
            "_________________________________________________________________\n",
            "CamadaClassificacao (Dense)  (None, 1)                 201       \n",
            "=================================================================\n",
            "Total params: 2,458,001\n",
            "Trainable params: 2,458,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "7/7 [==============================] - 1s 17ms/step - loss: 1535.8176\n",
            "Epoch 2/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 307.5937\n",
            "Epoch 3/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 112.6771\n",
            "Epoch 4/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 80.6408\n",
            "Epoch 5/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 50.2477\n",
            "Epoch 6/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 35.6524\n",
            "Epoch 7/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 17.1523\n",
            "Epoch 8/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 18.4048\n",
            "Epoch 9/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 9.1601\n",
            "Epoch 10/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 6.5833\n",
            "Epoch 11/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 6.6883\n",
            "Epoch 12/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 14.6948\n",
            "Epoch 13/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 15.1945\n",
            "Epoch 14/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 16.6987\n",
            "Epoch 15/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 12.3382\n",
            "Epoch 16/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 9.3483\n",
            "Epoch 17/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 7.0092\n",
            "Epoch 18/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 5.8204\n",
            "Epoch 19/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 3.6202\n",
            "Epoch 20/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 5.6704\n",
            "Epoch 21/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 2.1381\n",
            "Epoch 22/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 5.0330\n",
            "Epoch 23/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 2.1284\n",
            "Epoch 24/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 1.2618\n",
            "Epoch 25/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 1.5715\n",
            "Epoch 26/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.7299\n",
            "Epoch 27/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.3349\n",
            "Epoch 28/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 1.0097\n",
            "Epoch 29/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.2295\n",
            "Epoch 30/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.1573\n",
            "Epoch 31/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 2.2296\n",
            "Epoch 32/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 6.7704\n",
            "Epoch 33/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 2.4215\n",
            "Epoch 34/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.5852\n",
            "Epoch 35/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.7176\n",
            "Epoch 36/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.3943\n",
            "Epoch 37/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 2.0240\n",
            "Epoch 38/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 1.7637\n",
            "Epoch 39/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 2.9154\n",
            "Epoch 40/100\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 2.1932\n",
            "Epoch 41/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 6.9642\n",
            "Epoch 42/100\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 6.0169\n",
            "Epoch 43/100\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 4.1257\n",
            "Epoch 44/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 5.5209\n",
            "Epoch 45/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 4.6469\n",
            "Epoch 46/100\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 3.0500\n",
            "Epoch 47/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 4.6536\n",
            "Epoch 48/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 1.1361\n",
            "Epoch 49/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.3980\n",
            "Epoch 50/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.1009\n",
            "Epoch 51/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.1305\n",
            "Epoch 52/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.6892\n",
            "Epoch 53/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.1123\n",
            "Epoch 54/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0360\n",
            "Epoch 55/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0991\n",
            "Epoch 56/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.2096\n",
            "Epoch 57/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.0296\n",
            "Epoch 58/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0226\n",
            "Epoch 59/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0601\n",
            "Epoch 60/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0379\n",
            "Epoch 61/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0131\n",
            "Epoch 62/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0252\n",
            "Epoch 63/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 4.6673e-04\n",
            "Epoch 64/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0028\n",
            "Epoch 65/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0016\n",
            "Epoch 66/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 7.2097e-05\n",
            "Epoch 67/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 6.0701e-06\n",
            "Epoch 68/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 3.1304e-06\n",
            "Epoch 69/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 1.8682e-06\n",
            "Epoch 70/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 1.6897e-06\n",
            "Epoch 71/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 1.5456e-06\n",
            "Epoch 72/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 1.5197e-06\n",
            "Epoch 73/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 1.5074e-06\n",
            "Epoch 74/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 1.4961e-06\n",
            "Epoch 75/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 1.4910e-06\n",
            "Epoch 76/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 1.4879e-06\n",
            "Epoch 77/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 1.4847e-06\n",
            "Epoch 78/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 1.4819e-06\n",
            "Epoch 79/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 1.4794e-06\n",
            "Epoch 80/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 1.4766e-06\n",
            "Epoch 81/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 1.4737e-06\n",
            "Epoch 82/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 1.4715e-06\n",
            "Epoch 83/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 1.4686e-06\n",
            "Epoch 84/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 1.4657e-06\n",
            "Epoch 85/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 1.4644e-06\n",
            "Epoch 86/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 1.4610e-06\n",
            "Epoch 87/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 1.4586e-06\n",
            "Epoch 88/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 1.4560e-06\n",
            "Epoch 89/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 1.4540e-06\n",
            "Epoch 90/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 1.4516e-06\n",
            "Epoch 91/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 1.4493e-06\n",
            "Epoch 92/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 1.4469e-06\n",
            "Epoch 93/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 1.4445e-06\n",
            "Epoch 94/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 1.4419e-06\n",
            "Epoch 95/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 1.4395e-06\n",
            "Epoch 96/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 1.4375e-06\n",
            "Epoch 97/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 1.4341e-06\n",
            "Epoch 98/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 1.4323e-06\n",
            "Epoch 99/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 1.4289e-06\n",
            "Epoch 100/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 1.4258e-06\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f29d1020690>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Use os parâmetros treinados** para classificar as imagens de treinamento e teste e verificar a acurácia. "
      ],
      "metadata": {
        "id": "kDD6NfugFeLW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Predição da rede\n",
        "print(f'Acurácia no treino: {accuracy_score(treino_y.reshape(-1), np.round(model.predict(treino_x))) * 100:.2f}')\n",
        "print(f'Acurácia no teste: {accuracy_score(teste_y.reshape(-1), np.round(model.predict(teste_x))) * 100:.2f}')"
      ],
      "metadata": {
        "id": "U1cNTFT7Fhsm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a490f11-8cef-4e2d-d4c2-4548dbc1b9ca"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia no treino: 100.00\n",
            "Acurácia no teste: 68.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Resultado esperado:**\n",
        "\n",
        "```\n",
        "  Acurácia treino = 100%\n",
        "  Acurácia teste = 64%\n",
        "```"
      ],
      "metadata": {
        "id": "aW8vLiI_Fi5N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **ToDo:** Análise dos resultados (5pt)"
      ],
      "metadata": {
        "id": "A_OovF79qCJ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por que você obteve 100% no treino e apenas 64% no teste?\n",
        "\n",
        "`Porque a rede neural ficou muito sobreajustada aos dados de treino e não conseguiu acertar bem os dados de teste, houve um overfitting.`"
      ],
      "metadata": {
        "id": "3bWjvsXnqJZ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testando com uma rede com três camadas ocultas\n",
        "\n",
        "![Arq,widht=10](https://drive.google.com/uc?export=view&id=19h9LuWkWLVMYgAAoQKTfjJ-Er-tlw8En)\n",
        "<caption><center> <u>Figura 8</u>: Rede neural com L camadas. <br> Resumo do modelo: ***ENTRADA -> LINEAR -> RELU -> LINEAR -> SIGMOID -> SAIDA***. </center></caption>"
      ],
      "metadata": {
        "id": "1dMTm9d1Flqe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Setando a seed\n",
        "np.random.seed(1)\n",
        "random.seed(1)\n",
        "\n",
        "### Executar uma rede de 3 camadas ocultas ###\n",
        "# Camadas da rede = [12288, 200, 70, 5, 1] \n",
        "\n",
        "# Definição do modelo\n",
        "model = Sequential()\n",
        "model.add(Dense(200, input_shape=(12288,), activation='relu', name='CamadaOculta1'))\n",
        "model.add(Dense(70, activation='relu', name='CamadaOculta2'))\n",
        "model.add(Dense(5, activation='relu', name='CamadaOculta3'))\n",
        "model.add(Dense(1, activation='sigmoid', name='CamadaClassificacao'))\n",
        "\n",
        "# Compilando o modelo\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "\n",
        "# Imprimindo a arquitetura da rede proposta\n",
        "model.summary()\n",
        "\n",
        "# Treinando o modelo\n",
        "model.fit(treino_x, treino_y.reshape(-1), epochs=50)"
      ],
      "metadata": {
        "id": "5UgvfGmaFodF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92d13541-1db6-4115-b14c-14d11792225e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "CamadaOculta1 (Dense)        (None, 200)               2457800   \n",
            "_________________________________________________________________\n",
            "CamadaOculta2 (Dense)        (None, 70)                14070     \n",
            "_________________________________________________________________\n",
            "CamadaOculta3 (Dense)        (None, 5)                 355       \n",
            "_________________________________________________________________\n",
            "CamadaClassificacao (Dense)  (None, 1)                 6         \n",
            "=================================================================\n",
            "Total params: 2,472,231\n",
            "Trainable params: 2,472,231\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "7/7 [==============================] - 1s 21ms/step - loss: 78.2490\n",
            "Epoch 2/50\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.6926\n",
            "Epoch 3/50\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.6919\n",
            "Epoch 4/50\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.6912\n",
            "Epoch 5/50\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.6905\n",
            "Epoch 6/50\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.6897\n",
            "Epoch 7/50\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.6890\n",
            "Epoch 8/50\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.6882\n",
            "Epoch 9/50\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.6874\n",
            "Epoch 10/50\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.6866\n",
            "Epoch 11/50\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.6858\n",
            "Epoch 12/50\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.6851\n",
            "Epoch 13/50\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.6844\n",
            "Epoch 14/50\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.6837\n",
            "Epoch 15/50\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.6829\n",
            "Epoch 16/50\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.6821\n",
            "Epoch 17/50\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.6814\n",
            "Epoch 18/50\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.6807\n",
            "Epoch 19/50\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.6799\n",
            "Epoch 20/50\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.6793\n",
            "Epoch 21/50\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.6787\n",
            "Epoch 22/50\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.6780\n",
            "Epoch 23/50\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.6774\n",
            "Epoch 24/50\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.6767\n",
            "Epoch 25/50\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.6760\n",
            "Epoch 26/50\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.6754\n",
            "Epoch 27/50\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.6748\n",
            "Epoch 28/50\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.6741\n",
            "Epoch 29/50\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.6735\n",
            "Epoch 30/50\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.6729\n",
            "Epoch 31/50\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.6724\n",
            "Epoch 32/50\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.6717\n",
            "Epoch 33/50\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.6712\n",
            "Epoch 34/50\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.6706\n",
            "Epoch 35/50\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.6701\n",
            "Epoch 36/50\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.6694\n",
            "Epoch 37/50\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.6689\n",
            "Epoch 38/50\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.6685\n",
            "Epoch 39/50\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.6679\n",
            "Epoch 40/50\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.6674\n",
            "Epoch 41/50\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.6670\n",
            "Epoch 42/50\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 0.6664\n",
            "Epoch 43/50\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.6661\n",
            "Epoch 44/50\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.6656\n",
            "Epoch 45/50\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.6651\n",
            "Epoch 46/50\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.6648\n",
            "Epoch 47/50\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.6643\n",
            "Epoch 48/50\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.6639\n",
            "Epoch 49/50\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.6634\n",
            "Epoch 50/50\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.6630\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f34f3070f50>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Use os parâmetros treinados** para classificar as imagens de treinamento e teste e verificar a acurácia. "
      ],
      "metadata": {
        "id": "T6AJu8Wkr2bZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Predição da rede\n",
        "print(f'Train accuracy: {accuracy_score(treino_y.reshape(-1), np.round(model.predict(treino_x))) * 100:.2f}')\n",
        "print(f'Test accuracy: {accuracy_score(teste_y.reshape(-1), np.round(model.predict(teste_x))) * 100:.2f}')"
      ],
      "metadata": {
        "id": "vNzeSuJar2bk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f18391dc-3d72-4085-9a00-6a049fa3331e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy: 65.55\n",
            "Train accuracy: 34.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Resultado esperado:**\n",
        "\n",
        "```\n",
        "  Acurácia treino = 65.55%\n",
        "  Acurácia teste = 34.00%\n",
        "```"
      ],
      "metadata": {
        "id": "fHi53htGr2bk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **ToDo:** Análise dos resultados (5pt)"
      ],
      "metadata": {
        "id": "lCP6zT4kr2bk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O resultado com três camadas ocultas foi melhor ou pior do que usa somente uma camada? Tente explicar os motivos.\n",
        "\n",
        "\n",
        "`Foi pior, errou mais no conjunto de treino e de teste. Isso aconteceu porque a informação passadas pelas múltiplas camadas alteravam muito os pesos, impedindo o modelo de aprender.`"
      ],
      "metadata": {
        "id": "1vZ5Z64sr2bl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ToDo:** Teste uma rede (20pt)"
      ],
      "metadata": {
        "id": "DHbO2jtCuGKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Crie uma arquitetura e treine/teste o seu modelo"
      ],
      "metadata": {
        "id": "nSMAk900uItw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Início do código ###\n",
        "## Setando a seed\n",
        "np.random.seed(1)\n",
        "random.seed(1)\n",
        "\n",
        "### Executar uma rede de 1 camada oculta ###\n",
        "# Camadas da rede = [12288, 8193, 1] \n",
        "\n",
        "# Definição do modelo\n",
        "model2 = Sequential()\n",
        "model2.add(Dense(8193, input_shape=(12288,), activation='relu', name='CamadaOculta'))\n",
        "model2.add(Dense(1, activation='sigmoid', name='CamadaClassificacao'))\n",
        "\n",
        "# Compilando o modelo\n",
        "model2.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "\n",
        "# Imprimindo a arquitetura da rede proposta\n",
        "model2.summary()\n",
        "\n",
        "# Treinando o modelo\n",
        "model2.fit(treino_x, treino_y.reshape(-1), epochs=100)\n",
        "### Fim do código ###\n",
        "\n",
        "## Predição da rede\n",
        "print(f'Train accuracy: {accuracy_score(treino_y.reshape(-1), np.round(model2.predict(treino_x))) * 100:.2f}')\n",
        "print(f'Test accuracy: {accuracy_score(teste_y.reshape(-1), np.round(model2.predict(teste_x))) * 100:.2f}')"
      ],
      "metadata": {
        "id": "6CEoCnZVuetY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c7bb011-f7d2-48c4-8ad1-afebb54f365e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "CamadaOculta (Dense)         (None, 8193)              100683777 \n",
            "_________________________________________________________________\n",
            "CamadaClassificacao (Dense)  (None, 1)                 8194      \n",
            "=================================================================\n",
            "Total params: 100,691,971\n",
            "Trainable params: 100,691,971\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "7/7 [==============================] - 7s 865ms/step - loss: 9782.3916\n",
            "Epoch 2/100\n",
            "7/7 [==============================] - 7s 1s/step - loss: 3788.6687\n",
            "Epoch 3/100\n",
            "7/7 [==============================] - 5s 713ms/step - loss: 2056.2996\n",
            "Epoch 4/100\n",
            "7/7 [==============================] - 4s 604ms/step - loss: 1779.8491\n",
            "Epoch 5/100\n",
            "7/7 [==============================] - 4s 578ms/step - loss: 940.6163\n",
            "Epoch 6/100\n",
            "7/7 [==============================] - 5s 666ms/step - loss: 328.7968\n",
            "Epoch 7/100\n",
            "7/7 [==============================] - 4s 574ms/step - loss: 115.1862\n",
            "Epoch 8/100\n",
            "7/7 [==============================] - 4s 557ms/step - loss: 76.3696\n",
            "Epoch 9/100\n",
            "7/7 [==============================] - 4s 615ms/step - loss: 86.0029\n",
            "Epoch 10/100\n",
            "7/7 [==============================] - 5s 707ms/step - loss: 63.1600\n",
            "Epoch 11/100\n",
            "7/7 [==============================] - 5s 700ms/step - loss: 21.9293\n",
            "Epoch 12/100\n",
            "7/7 [==============================] - 5s 645ms/step - loss: 12.0855\n",
            "Epoch 13/100\n",
            "7/7 [==============================] - 4s 617ms/step - loss: 10.2778\n",
            "Epoch 14/100\n",
            "7/7 [==============================] - 4s 615ms/step - loss: 9.5082\n",
            "Epoch 15/100\n",
            "7/7 [==============================] - 5s 689ms/step - loss: 7.3316\n",
            "Epoch 16/100\n",
            "7/7 [==============================] - 5s 649ms/step - loss: 12.0615\n",
            "Epoch 17/100\n",
            "7/7 [==============================] - 5s 684ms/step - loss: 3.4139\n",
            "Epoch 18/100\n",
            "7/7 [==============================] - 4s 568ms/step - loss: 4.7067\n",
            "Epoch 19/100\n",
            "7/7 [==============================] - 5s 718ms/step - loss: 3.3617\n",
            "Epoch 20/100\n",
            "7/7 [==============================] - 5s 684ms/step - loss: 1.3940\n",
            "Epoch 21/100\n",
            "7/7 [==============================] - 5s 818ms/step - loss: 1.7054\n",
            "Epoch 22/100\n",
            "7/7 [==============================] - 4s 578ms/step - loss: 2.3280\n",
            "Epoch 23/100\n",
            "7/7 [==============================] - 4s 576ms/step - loss: 0.5614\n",
            "Epoch 24/100\n",
            "7/7 [==============================] - 4s 597ms/step - loss: 1.8575\n",
            "Epoch 25/100\n",
            "7/7 [==============================] - 5s 693ms/step - loss: 8.6892\n",
            "Epoch 26/100\n",
            "7/7 [==============================] - 6s 842ms/step - loss: 3.9302\n",
            "Epoch 27/100\n",
            "7/7 [==============================] - 5s 680ms/step - loss: 0.4770\n",
            "Epoch 28/100\n",
            "7/7 [==============================] - 5s 653ms/step - loss: 0.1904\n",
            "Epoch 29/100\n",
            "7/7 [==============================] - 5s 661ms/step - loss: 0.7573\n",
            "Epoch 30/100\n",
            "7/7 [==============================] - 4s 616ms/step - loss: 0.5970\n",
            "Epoch 31/100\n",
            "7/7 [==============================] - 4s 569ms/step - loss: 6.5111\n",
            "Epoch 32/100\n",
            "7/7 [==============================] - 4s 569ms/step - loss: 7.9555\n",
            "Epoch 33/100\n",
            "7/7 [==============================] - 5s 660ms/step - loss: 19.9945\n",
            "Epoch 34/100\n",
            "7/7 [==============================] - 4s 566ms/step - loss: 7.7461\n",
            "Epoch 35/100\n",
            "7/7 [==============================] - 5s 695ms/step - loss: 3.8187\n",
            "Epoch 36/100\n",
            "7/7 [==============================] - 5s 635ms/step - loss: 7.6611\n",
            "Epoch 37/100\n",
            "7/7 [==============================] - 5s 710ms/step - loss: 7.4516\n",
            "Epoch 38/100\n",
            "7/7 [==============================] - 5s 671ms/step - loss: 13.0197\n",
            "Epoch 39/100\n",
            "7/7 [==============================] - 4s 624ms/step - loss: 21.7920\n",
            "Epoch 40/100\n",
            "7/7 [==============================] - 5s 697ms/step - loss: 17.6545\n",
            "Epoch 41/100\n",
            "7/7 [==============================] - 5s 642ms/step - loss: 13.1280\n",
            "Epoch 42/100\n",
            "7/7 [==============================] - 5s 718ms/step - loss: 2.4773\n",
            "Epoch 43/100\n",
            "7/7 [==============================] - 5s 704ms/step - loss: 3.9202\n",
            "Epoch 44/100\n",
            "7/7 [==============================] - 5s 735ms/step - loss: 6.2896\n",
            "Epoch 45/100\n",
            "7/7 [==============================] - 4s 604ms/step - loss: 0.6167\n",
            "Epoch 46/100\n",
            "7/7 [==============================] - 5s 656ms/step - loss: 10.4663\n",
            "Epoch 47/100\n",
            "7/7 [==============================] - 4s 566ms/step - loss: 24.7189\n",
            "Epoch 48/100\n",
            "7/7 [==============================] - 5s 703ms/step - loss: 42.7997\n",
            "Epoch 49/100\n",
            "7/7 [==============================] - 6s 921ms/step - loss: 31.6551\n",
            "Epoch 50/100\n",
            "7/7 [==============================] - 5s 658ms/step - loss: 8.9111\n",
            "Epoch 51/100\n",
            "7/7 [==============================] - 4s 592ms/step - loss: 5.0569\n",
            "Epoch 52/100\n",
            "7/7 [==============================] - 5s 660ms/step - loss: 0.7592\n",
            "Epoch 53/100\n",
            "7/7 [==============================] - 5s 702ms/step - loss: 1.7763\n",
            "Epoch 54/100\n",
            "7/7 [==============================] - 4s 570ms/step - loss: 1.8678\n",
            "Epoch 55/100\n",
            "7/7 [==============================] - 5s 674ms/step - loss: 4.1907\n",
            "Epoch 56/100\n",
            "7/7 [==============================] - 5s 708ms/step - loss: 11.1348\n",
            "Epoch 57/100\n",
            "7/7 [==============================] - 5s 651ms/step - loss: 3.9511\n",
            "Epoch 58/100\n",
            "7/7 [==============================] - 4s 596ms/step - loss: 1.2871\n",
            "Epoch 59/100\n",
            "7/7 [==============================] - 5s 672ms/step - loss: 0.2256\n",
            "Epoch 60/100\n",
            "7/7 [==============================] - 5s 656ms/step - loss: 0.1183\n",
            "Epoch 61/100\n",
            "7/7 [==============================] - 5s 682ms/step - loss: 0.4004\n",
            "Epoch 62/100\n",
            "7/7 [==============================] - 5s 684ms/step - loss: 0.6311\n",
            "Epoch 63/100\n",
            "7/7 [==============================] - 5s 710ms/step - loss: 0.1902\n",
            "Epoch 64/100\n",
            "7/7 [==============================] - 5s 692ms/step - loss: 0.9232\n",
            "Epoch 65/100\n",
            "7/7 [==============================] - 5s 687ms/step - loss: 2.0296\n",
            "Epoch 66/100\n",
            "7/7 [==============================] - 4s 626ms/step - loss: 3.2629\n",
            "Epoch 67/100\n",
            "7/7 [==============================] - 5s 714ms/step - loss: 8.0806\n",
            "Epoch 68/100\n",
            "7/7 [==============================] - 4s 648ms/step - loss: 14.9086\n",
            "Epoch 69/100\n",
            "7/7 [==============================] - 4s 636ms/step - loss: 5.7588\n",
            "Epoch 70/100\n",
            "7/7 [==============================] - 5s 720ms/step - loss: 8.2096\n",
            "Epoch 71/100\n",
            "7/7 [==============================] - 5s 720ms/step - loss: 7.4376\n",
            "Epoch 72/100\n",
            "7/7 [==============================] - 6s 896ms/step - loss: 10.2771\n",
            "Epoch 73/100\n",
            "7/7 [==============================] - 5s 639ms/step - loss: 3.0609\n",
            "Epoch 74/100\n",
            "7/7 [==============================] - 5s 684ms/step - loss: 2.4821\n",
            "Epoch 75/100\n",
            "7/7 [==============================] - 5s 636ms/step - loss: 2.1131\n",
            "Epoch 76/100\n",
            "7/7 [==============================] - 5s 716ms/step - loss: 1.8199\n",
            "Epoch 77/100\n",
            "7/7 [==============================] - 4s 601ms/step - loss: 1.3447\n",
            "Epoch 78/100\n",
            "7/7 [==============================] - 5s 636ms/step - loss: 0.4246\n",
            "Epoch 79/100\n",
            "7/7 [==============================] - 5s 687ms/step - loss: 0.7032\n",
            "Epoch 80/100\n",
            "7/7 [==============================] - 5s 696ms/step - loss: 1.5760e-04\n",
            "Epoch 81/100\n",
            "7/7 [==============================] - 5s 660ms/step - loss: 0.0631\n",
            "Epoch 82/100\n",
            "7/7 [==============================] - 5s 715ms/step - loss: 0.0191\n",
            "Epoch 83/100\n",
            "7/7 [==============================] - 4s 577ms/step - loss: 0.1038\n",
            "Epoch 84/100\n",
            "7/7 [==============================] - 4s 584ms/step - loss: 0.0961\n",
            "Epoch 85/100\n",
            "7/7 [==============================] - 4s 589ms/step - loss: 0.1032\n",
            "Epoch 86/100\n",
            "7/7 [==============================] - 4s 603ms/step - loss: 0.1483\n",
            "Epoch 87/100\n",
            "7/7 [==============================] - 4s 580ms/step - loss: 0.8147\n",
            "Epoch 88/100\n",
            "7/7 [==============================] - 4s 588ms/step - loss: 4.1796\n",
            "Epoch 89/100\n",
            "7/7 [==============================] - 5s 737ms/step - loss: 8.6958\n",
            "Epoch 90/100\n",
            "7/7 [==============================] - 5s 649ms/step - loss: 5.6132\n",
            "Epoch 91/100\n",
            "7/7 [==============================] - 5s 688ms/step - loss: 2.8586\n",
            "Epoch 92/100\n",
            "7/7 [==============================] - 5s 675ms/step - loss: 1.3394\n",
            "Epoch 93/100\n",
            "7/7 [==============================] - 5s 715ms/step - loss: 0.1700\n",
            "Epoch 94/100\n",
            "7/7 [==============================] - 5s 743ms/step - loss: 0.2610\n",
            "Epoch 95/100\n",
            "7/7 [==============================] - 6s 802ms/step - loss: 0.1660\n",
            "Epoch 96/100\n",
            "7/7 [==============================] - 5s 690ms/step - loss: 0.2263\n",
            "Epoch 97/100\n",
            "7/7 [==============================] - 5s 658ms/step - loss: 0.1650\n",
            "Epoch 98/100\n",
            "7/7 [==============================] - 5s 646ms/step - loss: 0.2181\n",
            "Epoch 99/100\n",
            "7/7 [==============================] - 5s 632ms/step - loss: 0.2300\n",
            "Epoch 100/100\n",
            "7/7 [==============================] - 4s 575ms/step - loss: 0.0724\n",
            "Train accuracy: 100.00\n",
            "Train accuracy: 74.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testando redes neurais e *softmax*"
      ],
      "metadata": {
        "id": "nLW4Tn0wuACf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para classificação de múltiplas classes, tem-se um neurônio de saída para cada classe (como ilustrado no exemplo da Figura 1) e deve-se usar a operação Softmax antes de se calcular o custo (entropia cruzada ou cross-entropy como no exemplo anterior). Consute o capítulo [3.6 do livro](http://d2l.ai/chapter_linear-networks/softmax-regression-scratch.html) para entender melhor.  No caso de se usar softmax, deve-se usar a função **one_hot** para transformar a saída em logits. \n",
        "\n",
        "A função **one_hot** transforma um escalar em um **hot encoder**, de acordo com o número de classes.\n",
        "\n",
        "![Arq,widht=10](https://drive.google.com/uc?export=view&id=1WV_4AT49bYcqsp6PB0FoO4p-gASo0bjL)<caption><center> <u>Figura 1</u>: Rede neural dois neurônios de saída. <br> </center></caption>"
      ],
      "metadata": {
        "id": "ZyCHRbdiwJyE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Função de **one-hot encoded**"
      ],
      "metadata": {
        "id": "6GrjPa-62gxr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2xg7Hq6uxDu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c14ee94-a394-4ff8-8ee3-560e254706a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
              "array([[1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "indices = [0, 1, 2]\n",
        "depth = 3\n",
        "tf.one_hot(indices, depth)  # output: [3 x 3]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Saída esperada** \n",
        "```\n",
        " [[1., 0., 0.],\n",
        "  [0., 1., 0.],\n",
        "  [0., 0., 1.]]\n",
        "```"
      ],
      "metadata": {
        "id": "YgKXpLtF4S-S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **ToDo**: Função one-hot encoded (5pt)"
      ],
      "metadata": {
        "id": "qu9JryOR4pd6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O que a função one-hot encoded faz com o vetor na prática?\n",
        "\n",
        "`Tranforma cada possível valor do vetor(rótulo) em um vetor do tamanho da quantidade de valores(rótulos) possíveis. Cada vetor produzido possui em suas posições os valores de 0 ou 1, onde 1 representa que um rótulo está ativo. O vetor na realidade vira um vetor com esses vetores (uma matriz).`"
      ],
      "metadata": {
        "id": "gBVFTf0B4wIi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Função **SoftMax**"
      ],
      "metadata": {
        "id": "KHbEReQI3qmd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A função softmax transforma a saída em uma distribuição de probabilidades. Assim, a soma de todas as saídas dos neurônio da última camada sempre vai ser igual a 1:\n",
        "\n",
        "$$\n",
        "softmax(\\mathbf{x}) = \\frac{1}{\\sum_{i=1}^{n}{e^{x_i}}}\n",
        "\\cdot\n",
        "\\begin{bmatrix}\n",
        "  e^{x_1}\\\\\\\\\n",
        "  e^{x_2}\\\\\\\\\n",
        "  \\vdots\\\\\\\\\n",
        "  e^{x_n}\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "o gradiente para o custo usando-se a função softmax é trivial de se calcular:\n",
        "\n",
        "$$dw = softmax(\\mathbf{y_{pred}}) - y$$"
      ],
      "metadata": {
        "id": "erJ3LuOL3tlE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "indices = [-1., 0., 1.]\n",
        "\n",
        "print(tf.nn.softmax(indices))"
      ],
      "metadata": {
        "id": "nad6cUnvxpT8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4fae784-69ec-4857-f547-7eb8cf9bd39d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([0.09003057 0.24472848 0.66524094], shape=(3,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Saída esperada**\n",
        "\n",
        "```\n",
        " [0.09003057, 0.24472848, 0.66524094]\n",
        "```"
      ],
      "metadata": {
        "id": "beanCE4k5wG7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perceba que esse código também funciona se você passar um lote (batch) de amostras"
      ],
      "metadata": {
        "id": "Pgqg9PZ36ox4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Veja a saída abaixo\n",
        "X = np.array([[10., 2., -3.],\n",
        "              [-1., 5., -20.]])\n",
        "print(tf.nn.softmax(X))"
      ],
      "metadata": {
        "id": "WjHEQGJu6Hsl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f73eee95-ff02-4213-faae-e12027884ee6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[9.99662391e-01 3.35349373e-04 2.25956630e-06]\n",
            " [2.47262316e-03 9.97527377e-01 1.38536042e-11]], shape=(2, 3), dtype=float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **ToDo**: Função softmax (5pt)"
      ],
      "metadata": {
        "id": "21eMWxsG58bL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O que a função softmax faz com o vetor na prática?\n",
        "\n",
        "`A função softmax transforma a saída em uma distribuição de probabilidades que somadas resulta em 1. Ela retorna um vetor como resultado, com a probabilidade(distribuição) de cada elemento do vetor passado como parâmetro. Quanto maior o elemento maior será sua probabilidade. Isso ajudará na classificação de múltiplas classes.`"
      ],
      "metadata": {
        "id": "YRxnTwkb6C5S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Função de erro"
      ],
      "metadata": {
        "id": "hhNNpVBB6wNp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Em seguida, deve-se computar o erro entre um vetor predito (**Y_pred**) e o vetor de real de rótulos (**Y_true**). para tal, deve-se usar cross entropy loss, ou verossimilhança negativa (negative log likelihood). A função **cross_entropy()** implementa a verossimilhança negativa.\n",
        "\n",
        "```\n",
        "tf.keras.losses.CategoricalCrossentropy()\n",
        "```"
      ],
      "metadata": {
        "id": "qKt43d7R6yjK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Erro de uma predição bem ruim"
      ],
      "metadata": {
        "id": "-Gx0rUoI7P1Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = [[1, 0, 0]]\n",
        "y_pred = [[0.12, 4, 10]]\n",
        "\n",
        "cce = tf.keras.losses.CategoricalCrossentropy()\n",
        "print(cce(y_true, y_pred).numpy())\n"
      ],
      "metadata": {
        "id": "DR7ohEns7GaQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "453d7e2e-b4bd-4bd2-ef1a-c11dc03e23e9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.7678556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Erro de uma boa predição"
      ],
      "metadata": {
        "id": "YT6HvzKl7lGh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = [[1, 0, 0]]\n",
        "y_pred = [[0.97, 0.01, 0.02]]\n",
        "\n",
        "cce = tf.keras.losses.CategoricalCrossentropy()\n",
        "print(cce(y_true, y_pred).numpy())\n"
      ],
      "metadata": {
        "id": "wNmmHTQW7ZTR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a815f28-6f3c-45bc-9218-47ca9bff6aab"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.030459179\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A função de erro também funciona para um lote de dados."
      ],
      "metadata": {
        "id": "eP8T_fb77yJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = np.array([[0, 1, 0],\n",
        "                   [1, 0, 0],\n",
        "                   [0, 0, 1]])\n",
        "\n",
        "y_pred = np.array([[0,   1,    0],\n",
        "                   [.99, 0.01, 0],\n",
        "                   [0,   0,    1]])\n",
        "\n",
        "cce = tf.keras.losses.CategoricalCrossentropy()\n",
        "print(cce(y_true, y_pred).numpy())\n"
      ],
      "metadata": {
        "id": "sE_b6Bgz71f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98c2ed33-4ef4-4e4c-8652-48c6b9fcb27e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0033501784782856703\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **ToDo:** Função de erro (5pt)"
      ],
      "metadata": {
        "id": "QvZF40Ae8XuB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explique a função de erro *Categorical Cross-entropy*.\n",
        "\n",
        "`Ela calcula a perda de entropia cruzada entre os rótulos e as previsões, ou seja, é a medida da diferença entre duas distribuições, no caso a real e a predita. A função de perda requer as seguintes entradas: y_true(rótulo verdadeiro): isso é 0 ou 1,\n",
        "y_pred(valor previsto): previsão do modelo, ou seja, um único valor de ponto flutuante.`"
      ],
      "metadata": {
        "id": "UPfkas5T8fHK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testando uma rede com uma camada oculta"
      ],
      "metadata": {
        "id": "9H3VHpg184Qx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para esta atividade você deve usar uma loss (ou função de perda) baseada em softmax.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3o05cC_F9M7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Setando a seed\n",
        "np.random.seed(1)\n",
        "random.seed(1)\n",
        "\n",
        "### Executar uma rede de 1 camada oculta ###\n",
        "# Camadas da rede = [12288, 200, 1] \n",
        "\n",
        "# Definição do modelo\n",
        "model = Sequential()\n",
        "model.add(Dense(200, input_shape=(12288,), activation='relu', name='CamadaOculta'))\n",
        "model.add(Dense(2, activation='softmax', name='CamadaClassificacao'))\n",
        "\n",
        "# Compilando o modelo\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "# Imprimindo a arquitetura da rede proposta\n",
        "model.summary()\n",
        "\n",
        "# Treinando o modelo\n",
        "model.fit(treino_x, tf.one_hot(treino_y.reshape(-1), 2), epochs=100)"
      ],
      "metadata": {
        "id": "7nE260kJvVbd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff568945-c06e-41f4-84a5-a9041c5ae79b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "CamadaOculta (Dense)         (None, 200)               2457800   \n",
            "_________________________________________________________________\n",
            "CamadaClassificacao (Dense)  (None, 2)                 402       \n",
            "=================================================================\n",
            "Total params: 2,458,202\n",
            "Trainable params: 2,458,202\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 1801.8815\n",
            "Epoch 2/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 474.2288\n",
            "Epoch 3/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 235.8729\n",
            "Epoch 4/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 182.7170\n",
            "Epoch 5/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 65.2800\n",
            "Epoch 6/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 45.2471\n",
            "Epoch 7/100\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 42.5628\n",
            "Epoch 8/100\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 29.9993\n",
            "Epoch 9/100\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 47.8080\n",
            "Epoch 10/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 13.9710\n",
            "Epoch 11/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 9.2928\n",
            "Epoch 12/100\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 7.3784\n",
            "Epoch 13/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 2.6652\n",
            "Epoch 14/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 5.2736\n",
            "Epoch 15/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 3.9619\n",
            "Epoch 16/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 5.3285\n",
            "Epoch 17/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 1.8802\n",
            "Epoch 18/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 1.2801\n",
            "Epoch 19/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 1.6448\n",
            "Epoch 20/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 5.1547\n",
            "Epoch 21/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 5.8529\n",
            "Epoch 22/100\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 3.2894\n",
            "Epoch 23/100\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 1.7633\n",
            "Epoch 24/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 6.7933\n",
            "Epoch 25/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 3.8641\n",
            "Epoch 26/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 1.9624\n",
            "Epoch 27/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 1.7115\n",
            "Epoch 28/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 6.3686\n",
            "Epoch 29/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.6546\n",
            "Epoch 30/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.6452\n",
            "Epoch 31/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 17.9736\n",
            "Epoch 32/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 9.9689\n",
            "Epoch 33/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 21.5005\n",
            "Epoch 34/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 28.3850\n",
            "Epoch 35/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 4.5958\n",
            "Epoch 36/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 7.9240\n",
            "Epoch 37/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 3.8711\n",
            "Epoch 38/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 6.9640\n",
            "Epoch 39/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 12.0132\n",
            "Epoch 40/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 7.3962\n",
            "Epoch 41/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 12.3544\n",
            "Epoch 42/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 3.8277\n",
            "Epoch 43/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.9419\n",
            "Epoch 44/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 8.2277\n",
            "Epoch 45/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 2.9087\n",
            "Epoch 46/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 4.4333\n",
            "Epoch 47/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 1.1672\n",
            "Epoch 48/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.4678\n",
            "Epoch 49/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 1.1084\n",
            "Epoch 50/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 4.1968\n",
            "Epoch 51/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 4.1626\n",
            "Epoch 52/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 1.9273\n",
            "Epoch 53/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.8222\n",
            "Epoch 54/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.1440\n",
            "Epoch 55/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 1.5554\n",
            "Epoch 56/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 3.3536\n",
            "Epoch 57/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.6949\n",
            "Epoch 58/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0328\n",
            "Epoch 59/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.3164\n",
            "Epoch 60/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.3408\n",
            "Epoch 61/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 3.7032\n",
            "Epoch 62/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 12.4676\n",
            "Epoch 63/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 32.8054\n",
            "Epoch 64/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 30.4529\n",
            "Epoch 65/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 28.4256\n",
            "Epoch 66/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 11.8998\n",
            "Epoch 67/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 4.4435\n",
            "Epoch 68/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 2.4682\n",
            "Epoch 69/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.8535\n",
            "Epoch 70/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.1792\n",
            "Epoch 71/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.1061\n",
            "Epoch 72/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.4757\n",
            "Epoch 73/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.6915\n",
            "Epoch 74/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.3287\n",
            "Epoch 75/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.6772\n",
            "Epoch 76/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.5357\n",
            "Epoch 77/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.3576\n",
            "Epoch 78/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0651\n",
            "Epoch 79/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.3033\n",
            "Epoch 80/100\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.2656\n",
            "Epoch 81/100\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.3142\n",
            "Epoch 82/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.8101\n",
            "Epoch 83/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.3141\n",
            "Epoch 84/100\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1453\n",
            "Epoch 85/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.1309\n",
            "Epoch 86/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.0107\n",
            "Epoch 87/100\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 2.1185e-04\n",
            "Epoch 88/100\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.2543\n",
            "Epoch 89/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.2017\n",
            "Epoch 90/100\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 6.7304e-08\n",
            "Epoch 91/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.1287\n",
            "Epoch 92/100\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.0237\n",
            "Epoch 93/100\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.0000e+00\n",
            "Epoch 94/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 1.4454e-05\n",
            "Epoch 95/100\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.0084\n",
            "Epoch 96/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.0199\n",
            "Epoch 97/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0250\n",
            "Epoch 98/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 6.9586e-08\n",
            "Epoch 99/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 5.7038e-09\n",
            "Epoch 100/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 3.9785e-06\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f29d0abd150>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Use os parâmetros treinados** para classificar as imagens de treinamento e teste e verificar a acurácia. "
      ],
      "metadata": {
        "id": "9AnMRktBvVbe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Predição da rede\n",
        "print(f'Acurácia no treino: {accuracy_score(treino_y.reshape(-1), np.argmax(model.predict(treino_x), axis=1)) * 100:.2f}')\n",
        "print(f'Acurácia no teste: {accuracy_score(teste_y.reshape(-1), np.argmax(model.predict(teste_x), axis=1)) * 100:.2f}')"
      ],
      "metadata": {
        "id": "t5m66CIevVbf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8baa53bb-2ec8-49d1-da28-1e9e02695ceb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia no treino: 100.00\n",
            "Acurácia no teste: 70.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Resultado esperado:**\n",
        "\n",
        "```\n",
        "  Acurácia treino = 100%\n",
        "  Acurácia teste = 70%\n",
        "```"
      ],
      "metadata": {
        "id": "-FIWyjRWvVbg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ToDo:** Testando outras redes (20pt)"
      ],
      "metadata": {
        "id": "1sek10TPwa3p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primero, implemente a rede de três camadas ocultas (mesma arquitetura utilizada com sigmoid). Por fim, repita o teste com uma arquitetura projetada por você, de preferência, bem profunda e mais larga.\n",
        "Plote a curva de custo (epochs vs loss) para cada um dos dois casos. O que você conclui?"
      ],
      "metadata": {
        "id": "-L9b-0Cx9Kvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Início do código ###\n",
        "## Setando a seed\n",
        "## Setando a seed\n",
        "np.random.seed(1)\n",
        "random.seed(1)\n",
        "\n",
        "### Executar uma rede de 3 camadas ocultas ###\n",
        "# Camadas da rede = [12288, 200, 70, 5, 2] \n",
        "\n",
        "# Definição do modelo\n",
        "model = Sequential()\n",
        "model.add(Dense(200, input_shape=(12288,), activation='relu', name='CamadaOculta1'))\n",
        "model.add(Dense(70, activation='relu', name='CamadaOculta2'))\n",
        "model.add(Dense(5, activation='relu', name='CamadaOculta3'))\n",
        "model.add(Dense(2, activation='softmax', name='CamadaClassificacao'))\n",
        "\n",
        "# Compilando o modelo\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "# Imprimindo a arquitetura da rede proposta\n",
        "model.summary()\n",
        "\n",
        "# Treinando o modelo\n",
        "history = model.fit(treino_x, tf.one_hot(treino_y.reshape(-1), 2), epochs=100)\n",
        "### Fim do código ###\n",
        "\n",
        "## Predição da rede\n",
        "print(f'Acurácia no treino: {accuracy_score(treino_y.reshape(-1), np.argmax(model.predict(treino_x), axis=1)) * 100:.2f}')\n",
        "print(f'Acurácia no teste: {accuracy_score(teste_y.reshape(-1), np.argmax(model.predict(teste_x), axis=1)) * 100:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LH8CJBwyukt",
        "outputId": "0980217f-812a-4861-dd64-6dab2163fbcc"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_26\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "CamadaOculta1 (Dense)        (None, 200)               2457800   \n",
            "_________________________________________________________________\n",
            "CamadaOculta2 (Dense)        (None, 70)                14070     \n",
            "_________________________________________________________________\n",
            "CamadaOculta3 (Dense)        (None, 5)                 355       \n",
            "_________________________________________________________________\n",
            "CamadaClassificacao (Dense)  (None, 2)                 12        \n",
            "=================================================================\n",
            "Total params: 2,472,237\n",
            "Trainable params: 2,472,237\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "7/7 [==============================] - 1s 22ms/step - loss: 162.7314\n",
            "Epoch 2/100\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.6911\n",
            "Epoch 3/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.6898\n",
            "Epoch 4/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.6886\n",
            "Epoch 5/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.6875\n",
            "Epoch 6/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.6864\n",
            "Epoch 7/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.6851\n",
            "Epoch 8/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.6841\n",
            "Epoch 9/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.6829\n",
            "Epoch 10/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.6817\n",
            "Epoch 11/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.6805\n",
            "Epoch 12/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.6794\n",
            "Epoch 13/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.6783\n",
            "Epoch 14/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.6771\n",
            "Epoch 15/100\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.6759\n",
            "Epoch 16/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.6750\n",
            "Epoch 17/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.6738\n",
            "Epoch 18/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.6727\n",
            "Epoch 19/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.6716\n",
            "Epoch 20/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.6704\n",
            "Epoch 21/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.6695\n",
            "Epoch 22/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.6687\n",
            "Epoch 23/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.6676\n",
            "Epoch 24/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.6666\n",
            "Epoch 25/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.6658\n",
            "Epoch 26/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.6649\n",
            "Epoch 27/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.6641\n",
            "Epoch 28/100\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.6633\n",
            "Epoch 29/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.6624\n",
            "Epoch 30/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.6616\n",
            "Epoch 31/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.6610\n",
            "Epoch 32/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.6603\n",
            "Epoch 33/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.6595\n",
            "Epoch 34/100\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 0.6589\n",
            "Epoch 35/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.6584\n",
            "Epoch 36/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.6576\n",
            "Epoch 37/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.6570\n",
            "Epoch 38/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.6565\n",
            "Epoch 39/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.6558\n",
            "Epoch 40/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.6554\n",
            "Epoch 41/100\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 0.6549\n",
            "Epoch 42/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.6545\n",
            "Epoch 43/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.6541\n",
            "Epoch 44/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.6535\n",
            "Epoch 45/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.6532\n",
            "Epoch 46/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.6527\n",
            "Epoch 47/100\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.6524\n",
            "Epoch 48/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.6519\n",
            "Epoch 49/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.6516\n",
            "Epoch 50/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.6512\n",
            "Epoch 51/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.6509\n",
            "Epoch 52/100\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.6506\n",
            "Epoch 53/100\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.6502\n",
            "Epoch 54/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.6499\n",
            "Epoch 55/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.6497\n",
            "Epoch 56/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.6495\n",
            "Epoch 57/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.6491\n",
            "Epoch 58/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.6489\n",
            "Epoch 59/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.6487\n",
            "Epoch 60/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.6485\n",
            "Epoch 61/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.6482\n",
            "Epoch 62/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.6480\n",
            "Epoch 63/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.6479\n",
            "Epoch 64/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.6478\n",
            "Epoch 65/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.6475\n",
            "Epoch 66/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.6473\n",
            "Epoch 67/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.6472\n",
            "Epoch 68/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.6470\n",
            "Epoch 69/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.6469\n",
            "Epoch 70/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.6467\n",
            "Epoch 71/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.6466\n",
            "Epoch 72/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.6464\n",
            "Epoch 73/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.6463\n",
            "Epoch 74/100\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.6462\n",
            "Epoch 75/100\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.6461\n",
            "Epoch 76/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.6460\n",
            "Epoch 77/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.6459\n",
            "Epoch 78/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.6459\n",
            "Epoch 79/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.6457\n",
            "Epoch 80/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.6456\n",
            "Epoch 81/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.6455\n",
            "Epoch 82/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.6454\n",
            "Epoch 83/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.6453\n",
            "Epoch 84/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.6453\n",
            "Epoch 85/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.6452\n",
            "Epoch 86/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.6451\n",
            "Epoch 87/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.6451\n",
            "Epoch 88/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.6451\n",
            "Epoch 89/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.6449\n",
            "Epoch 90/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.6449\n",
            "Epoch 91/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.6448\n",
            "Epoch 92/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.6448\n",
            "Epoch 93/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.6447\n",
            "Epoch 94/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.6448\n",
            "Epoch 95/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.6446\n",
            "Epoch 96/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.6446\n",
            "Epoch 97/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.6446\n",
            "Epoch 98/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.6445\n",
            "Epoch 99/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.6445\n",
            "Epoch 100/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.6445\n",
            "Acurácia no treino: 65.55\n",
            "Acurácia no teste: 34.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.epoch, history.history['loss'], label=\"Distribuição do Erro\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "NdaThFOP8sje",
        "outputId": "bd12829f-e411-496c-a16a-568ebb2334ee"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Início do código ###\n",
        "## Setando a seed\n",
        "## Setando a seed\n",
        "np.random.seed(1)\n",
        "random.seed(1)\n",
        "\n",
        "### Executar uma rede de 7 camadas ocultas ###\n",
        "# Camadas da rede = [12288, 500, 200, 70, 50, 20, 10 5, 2] \n",
        "\n",
        "# Definição do modelo\n",
        "model = Sequential()\n",
        "model.add(Dense(500, input_shape=(12288,), activation='relu', name='CamadaOculta1'))\n",
        "model.add(Dense(200, activation='relu', name='CamadaOculta2'))\n",
        "model.add(Dense(70, activation='relu', name='CamadaOculta3'))\n",
        "model.add(Dense(50, activation='relu', name='CamadaOculta4'))\n",
        "model.add(Dense(10, activation='relu', name='CamadaOculta5'))\n",
        "model.add(Dense(5, activation='relu', name='CamadaOculta6'))\n",
        "model.add(Dense(2, activation='softmax', name='CamadaClassificacao'))\n",
        "\n",
        "# Compilando o modelo\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "# Imprimindo a arquitetura da rede proposta\n",
        "model.summary()\n",
        "\n",
        "# Treinando o modelo\n",
        "history = model.fit(treino_x, tf.one_hot(treino_y.reshape(-1), 2), epochs=100)\n",
        "### Fim do código ###\n",
        "\n",
        "## Predição da rede\n",
        "print(f'Acurácia no treino: {accuracy_score(treino_y.reshape(-1), np.argmax(model.predict(treino_x), axis=1)) * 100:.2f}')\n",
        "print(f'Acurácia no teste: {accuracy_score(teste_y.reshape(-1), np.argmax(model.predict(teste_x), axis=1)) * 100:.2f}')"
      ],
      "metadata": {
        "id": "vYZ0MjdS8SZ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e365fbd1-d658-400e-fc81-d145c361a2d8"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_28\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "CamadaOculta1 (Dense)        (None, 500)               6144500   \n",
            "_________________________________________________________________\n",
            "CamadaOculta2 (Dense)        (None, 200)               100200    \n",
            "_________________________________________________________________\n",
            "CamadaOculta3 (Dense)        (None, 70)                14070     \n",
            "_________________________________________________________________\n",
            "CamadaOculta4 (Dense)        (None, 50)                3550      \n",
            "_________________________________________________________________\n",
            "CamadaOculta5 (Dense)        (None, 10)                510       \n",
            "_________________________________________________________________\n",
            "CamadaOculta6 (Dense)        (None, 5)                 55        \n",
            "_________________________________________________________________\n",
            "CamadaClassificacao (Dense)  (None, 2)                 12        \n",
            "=================================================================\n",
            "Total params: 6,262,897\n",
            "Trainable params: 6,262,897\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "7/7 [==============================] - 1s 56ms/step - loss: 59.6930\n",
            "Epoch 2/100\n",
            "7/7 [==============================] - 0s 57ms/step - loss: 23.4013\n",
            "Epoch 3/100\n",
            "7/7 [==============================] - 0s 43ms/step - loss: 61.1982\n",
            "Epoch 4/100\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 21.6840\n",
            "Epoch 5/100\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 1.3065\n",
            "Epoch 6/100\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6899\n",
            "Epoch 7/100\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6889\n",
            "Epoch 8/100\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6880\n",
            "Epoch 9/100\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6872\n",
            "Epoch 10/100\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.6864\n",
            "Epoch 11/100\n",
            "7/7 [==============================] - 0s 42ms/step - loss: 0.6850\n",
            "Epoch 12/100\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6847\n",
            "Epoch 13/100\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.6822\n",
            "Epoch 14/100\n",
            "7/7 [==============================] - 0s 54ms/step - loss: 0.6825\n",
            "Epoch 15/100\n",
            "7/7 [==============================] - 0s 53ms/step - loss: 0.6809\n",
            "Epoch 16/100\n",
            "7/7 [==============================] - 0s 53ms/step - loss: 0.6794\n",
            "Epoch 17/100\n",
            "7/7 [==============================] - 0s 56ms/step - loss: 0.6784\n",
            "Epoch 18/100\n",
            "7/7 [==============================] - 0s 52ms/step - loss: 0.6771\n",
            "Epoch 19/100\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.6763\n",
            "Epoch 20/100\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.6752\n",
            "Epoch 21/100\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6744\n",
            "Epoch 22/100\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.6693\n",
            "Epoch 23/100\n",
            "7/7 [==============================] - 0s 56ms/step - loss: 0.6751\n",
            "Epoch 24/100\n",
            "7/7 [==============================] - 0s 56ms/step - loss: 0.6743\n",
            "Epoch 25/100\n",
            "7/7 [==============================] - 0s 50ms/step - loss: 0.6735\n",
            "Epoch 26/100\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.6727\n",
            "Epoch 27/100\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6719\n",
            "Epoch 28/100\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.6711\n",
            "Epoch 29/100\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6703\n",
            "Epoch 30/100\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6696\n",
            "Epoch 31/100\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6687\n",
            "Epoch 32/100\n",
            "7/7 [==============================] - 0s 42ms/step - loss: 0.6681\n",
            "Epoch 33/100\n",
            "7/7 [==============================] - 0s 70ms/step - loss: 0.6672\n",
            "Epoch 34/100\n",
            "7/7 [==============================] - 1s 95ms/step - loss: 0.6667\n",
            "Epoch 35/100\n",
            "7/7 [==============================] - 1s 77ms/step - loss: 0.6660\n",
            "Epoch 36/100\n",
            "7/7 [==============================] - 1s 90ms/step - loss: 0.6653\n",
            "Epoch 37/100\n",
            "7/7 [==============================] - 1s 108ms/step - loss: 0.6647\n",
            "Epoch 38/100\n",
            "7/7 [==============================] - 1s 111ms/step - loss: 0.6641\n",
            "Epoch 39/100\n",
            "7/7 [==============================] - 1s 103ms/step - loss: 0.6633\n",
            "Epoch 40/100\n",
            "7/7 [==============================] - 1s 107ms/step - loss: 0.6628\n",
            "Epoch 41/100\n",
            "7/7 [==============================] - 1s 88ms/step - loss: 0.6622\n",
            "Epoch 42/100\n",
            "7/7 [==============================] - 1s 92ms/step - loss: 0.6615\n",
            "Epoch 43/100\n",
            "7/7 [==============================] - 1s 76ms/step - loss: 0.6611\n",
            "Epoch 44/100\n",
            "7/7 [==============================] - 1s 78ms/step - loss: 0.6604\n",
            "Epoch 45/100\n",
            "7/7 [==============================] - 1s 82ms/step - loss: 0.6600\n",
            "Epoch 46/100\n",
            "7/7 [==============================] - 1s 77ms/step - loss: 0.6594\n",
            "Epoch 47/100\n",
            "7/7 [==============================] - 1s 79ms/step - loss: 0.6588\n",
            "Epoch 48/100\n",
            "7/7 [==============================] - 0s 70ms/step - loss: 0.6584\n",
            "Epoch 49/100\n",
            "7/7 [==============================] - 0s 60ms/step - loss: 0.6579\n",
            "Epoch 50/100\n",
            "7/7 [==============================] - 1s 72ms/step - loss: 0.6574\n",
            "Epoch 51/100\n",
            "7/7 [==============================] - 1s 79ms/step - loss: 0.6570\n",
            "Epoch 52/100\n",
            "7/7 [==============================] - 1s 71ms/step - loss: 0.6566\n",
            "Epoch 53/100\n",
            "7/7 [==============================] - 1s 73ms/step - loss: 0.6561\n",
            "Epoch 54/100\n",
            "7/7 [==============================] - 1s 71ms/step - loss: 0.6556\n",
            "Epoch 55/100\n",
            "7/7 [==============================] - 0s 72ms/step - loss: 0.6552\n",
            "Epoch 56/100\n",
            "7/7 [==============================] - 1s 91ms/step - loss: 0.6548\n",
            "Epoch 57/100\n",
            "7/7 [==============================] - 1s 97ms/step - loss: 0.6544\n",
            "Epoch 58/100\n",
            "7/7 [==============================] - 1s 90ms/step - loss: 0.6540\n",
            "Epoch 59/100\n",
            "7/7 [==============================] - 1s 79ms/step - loss: 0.6536\n",
            "Epoch 60/100\n",
            "7/7 [==============================] - 0s 66ms/step - loss: 0.6533\n",
            "Epoch 61/100\n",
            "7/7 [==============================] - 1s 77ms/step - loss: 0.6529\n",
            "Epoch 62/100\n",
            "7/7 [==============================] - 1s 128ms/step - loss: 0.6526\n",
            "Epoch 63/100\n",
            "7/7 [==============================] - 1s 104ms/step - loss: 0.6522\n",
            "Epoch 64/100\n",
            "7/7 [==============================] - 0s 59ms/step - loss: 0.6519\n",
            "Epoch 65/100\n",
            "7/7 [==============================] - 0s 53ms/step - loss: 0.6517\n",
            "Epoch 66/100\n",
            "7/7 [==============================] - 0s 56ms/step - loss: 0.6512\n",
            "Epoch 67/100\n",
            "7/7 [==============================] - 0s 59ms/step - loss: 0.6510\n",
            "Epoch 68/100\n",
            "7/7 [==============================] - 0s 56ms/step - loss: 0.6508\n",
            "Epoch 69/100\n",
            "7/7 [==============================] - 0s 56ms/step - loss: 0.6505\n",
            "Epoch 70/100\n",
            "7/7 [==============================] - 0s 53ms/step - loss: 0.6503\n",
            "Epoch 71/100\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6500\n",
            "Epoch 72/100\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.6498\n",
            "Epoch 73/100\n",
            "7/7 [==============================] - 0s 42ms/step - loss: 0.6496\n",
            "Epoch 74/100\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.6494\n",
            "Epoch 75/100\n",
            "7/7 [==============================] - 1s 123ms/step - loss: 0.6492\n",
            "Epoch 76/100\n",
            "7/7 [==============================] - 1s 136ms/step - loss: 0.6490\n",
            "Epoch 77/100\n",
            "7/7 [==============================] - 1s 83ms/step - loss: 0.6488\n",
            "Epoch 78/100\n",
            "7/7 [==============================] - 1s 86ms/step - loss: 0.6486\n",
            "Epoch 79/100\n",
            "7/7 [==============================] - 1s 91ms/step - loss: 0.6485\n",
            "Epoch 80/100\n",
            "7/7 [==============================] - 1s 77ms/step - loss: 0.6482\n",
            "Epoch 81/100\n",
            "7/7 [==============================] - 0s 66ms/step - loss: 0.6481\n",
            "Epoch 82/100\n",
            "7/7 [==============================] - 1s 78ms/step - loss: 0.6480\n",
            "Epoch 83/100\n",
            "7/7 [==============================] - 1s 83ms/step - loss: 0.6478\n",
            "Epoch 84/100\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 0.6477\n",
            "Epoch 85/100\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.6475\n",
            "Epoch 86/100\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.6474\n",
            "Epoch 87/100\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.6473\n",
            "Epoch 88/100\n",
            "7/7 [==============================] - 0s 58ms/step - loss: 0.6472\n",
            "Epoch 89/100\n",
            "7/7 [==============================] - 0s 56ms/step - loss: 0.6470\n",
            "Epoch 90/100\n",
            "7/7 [==============================] - 0s 56ms/step - loss: 0.6469\n",
            "Epoch 91/100\n",
            "7/7 [==============================] - 0s 52ms/step - loss: 0.6467\n",
            "Epoch 92/100\n",
            "7/7 [==============================] - 0s 56ms/step - loss: 0.6466\n",
            "Epoch 93/100\n",
            "7/7 [==============================] - 0s 57ms/step - loss: 0.6465\n",
            "Epoch 94/100\n",
            "7/7 [==============================] - 0s 54ms/step - loss: 0.6463\n",
            "Epoch 95/100\n",
            "7/7 [==============================] - 0s 60ms/step - loss: 0.6462\n",
            "Epoch 96/100\n",
            "7/7 [==============================] - 0s 57ms/step - loss: 0.6462\n",
            "Epoch 97/100\n",
            "7/7 [==============================] - 0s 57ms/step - loss: 0.6460\n",
            "Epoch 98/100\n",
            "7/7 [==============================] - 0s 55ms/step - loss: 0.6459\n",
            "Epoch 99/100\n",
            "7/7 [==============================] - 0s 53ms/step - loss: 0.6458\n",
            "Epoch 100/100\n",
            "7/7 [==============================] - 0s 58ms/step - loss: 0.6458\n",
            "Acurácia no treino: 65.55\n",
            "Acurácia no teste: 34.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.epoch, history.history['loss'], label=\"Distribuição do Erro\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "TNK7RpfT51l2",
        "outputId": "882ffd60-b21d-497c-cd35-65ffa897e56c"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f29c09257d0>]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "É possível concluir que em redes neurais mais largas e profundas o erro no início das épocas sofre mais variação para depois convergir a um determinado erro menor."
      ],
      "metadata": {
        "id": "X4h7iOdb-L4F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ToDo:** Variando alguns hiperparâmetros (20pt)"
      ],
      "metadata": {
        "id": "EEufLmq_w-li"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usando o framework do tensorflow/keras, altere os hiperparâmetros e veja o impacto (gere pelo menos dois novos modelos):\n",
        "\n",
        "- learning rate,\n",
        "- Algoritmo de otimização (SGD com momento, ADAM, ADADELTA, RMSPROP),\n",
        "- inicialização dos pesos: inicialiação aleatória vs uniforme,\n",
        "- Funções de ativação : troque a sigmoid por (ReLU, GELU, Leaky RELU),"
      ],
      "metadata": {
        "id": "7-DanKGBw3q5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Início do código ###\n",
        "## Setando a seed\n",
        "np.random.seed(1)\n",
        "random.seed(1)\n",
        "\n",
        "### Executar uma rede de 1 camada oculta ###\n",
        "# Camadas da rede = [12288, 200, 1] \n",
        "\n",
        "# Definição do modelo\n",
        "model = Sequential()\n",
        "model.add(Dense(200, input_shape=(12288,), activation='relu', name='CamadaOculta', kernel_initializer=initializers.RandomNormal(mean=0., stddev=1.)))\n",
        "model.add(Dense(1, activation='sigmoid', name='CamadaClassificacao'))\n",
        "\n",
        "# Compilando o modelo\n",
        "model.compile(loss='binary_crossentropy', optimizer='sgd')\n",
        "\n",
        "# Imprimindo a arquitetura da rede proposta\n",
        "model.summary()\n",
        "\n",
        "# Treinando o modelo\n",
        "model.fit(treino_x, treino_y.reshape(-1), epochs=100)\n",
        "### Fim do código ###\n",
        "\n",
        "## Predição da rede\n",
        "print(f'Acurácia no treino: {accuracy_score(treino_y.reshape(-1), np.round(model.predict(treino_x))) * 100:.2f}')\n",
        "print(f'Acurácia no teste: {accuracy_score(teste_y.reshape(-1), np.round(model.predict(teste_x))) * 100:.2f}')"
      ],
      "metadata": {
        "id": "FL_eSGkMyvUz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c1d6bf5-99b0-4c7c-944c-0dba773da241"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_34\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "CamadaOculta (Dense)         (None, 200)               2457800   \n",
            "_________________________________________________________________\n",
            "CamadaClassificacao (Dense)  (None, 1)                 201       \n",
            "=================================================================\n",
            "Total params: 2,458,001\n",
            "Trainable params: 2,458,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "7/7 [==============================] - 1s 18ms/step - loss: 38327348.0000\n",
            "Epoch 2/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 6015.2441\n",
            "Epoch 3/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 8.1164\n",
            "Epoch 4/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.6439\n",
            "Epoch 5/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.6428\n",
            "Epoch 6/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.6419\n",
            "Epoch 7/100\n",
            "7/7 [==============================] - 0s 34ms/step - loss: 0.6411\n",
            "Epoch 8/100\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.6403\n",
            "Epoch 9/100\n",
            "7/7 [==============================] - 0s 33ms/step - loss: 0.6396\n",
            "Epoch 10/100\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.6388\n",
            "Epoch 11/100\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.6381\n",
            "Epoch 12/100\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.6373\n",
            "Epoch 13/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.6366\n",
            "Epoch 14/100\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.6359\n",
            "Epoch 15/100\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.6353\n",
            "Epoch 16/100\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.6347\n",
            "Epoch 17/100\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.6341\n",
            "Epoch 18/100\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.6334\n",
            "Epoch 19/100\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.6329\n",
            "Epoch 20/100\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.6323\n",
            "Epoch 21/100\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.6317\n",
            "Epoch 22/100\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.6311\n",
            "Epoch 23/100\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.6306\n",
            "Epoch 24/100\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 0.6300\n",
            "Epoch 25/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.6295\n",
            "Epoch 26/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.6290\n",
            "Epoch 27/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.6286\n",
            "Epoch 28/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.6281\n",
            "Epoch 29/100\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.6277\n",
            "Epoch 30/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.6272\n",
            "Epoch 31/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.6269\n",
            "Epoch 32/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.6265\n",
            "Epoch 33/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.6261\n",
            "Epoch 34/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.6258\n",
            "Epoch 35/100\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.6254\n",
            "Epoch 36/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.6251\n",
            "Epoch 37/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.6248\n",
            "Epoch 38/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.6245\n",
            "Epoch 39/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.6242\n",
            "Epoch 40/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.6239\n",
            "Epoch 41/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.6236\n",
            "Epoch 42/100\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.6233\n",
            "Epoch 43/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.6230\n",
            "Epoch 44/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.6228\n",
            "Epoch 45/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.6225\n",
            "Epoch 46/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.6223\n",
            "Epoch 47/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.6220\n",
            "Epoch 48/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.6218\n",
            "Epoch 49/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.6216\n",
            "Epoch 50/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.6214\n",
            "Epoch 51/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.6211\n",
            "Epoch 52/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.6209\n",
            "Epoch 53/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.6207\n",
            "Epoch 54/100\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.6205\n",
            "Epoch 55/100\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.6204\n",
            "Epoch 56/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.6202\n",
            "Epoch 57/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.6200\n",
            "Epoch 58/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.6199\n",
            "Epoch 59/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.6197\n",
            "Epoch 60/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.6195\n",
            "Epoch 61/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6194\n",
            "Epoch 62/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.6192\n",
            "Epoch 63/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.6191\n",
            "Epoch 64/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6189\n",
            "Epoch 65/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.6188\n",
            "Epoch 66/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6187\n",
            "Epoch 67/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6185\n",
            "Epoch 68/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6184\n",
            "Epoch 69/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.6183\n",
            "Epoch 70/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.6182\n",
            "Epoch 71/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.6181\n",
            "Epoch 72/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.6180\n",
            "Epoch 73/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.6178\n",
            "Epoch 74/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.6177\n",
            "Epoch 75/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.6177\n",
            "Epoch 76/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.6176\n",
            "Epoch 77/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.6175\n",
            "Epoch 78/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.6174\n",
            "Epoch 79/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.6173\n",
            "Epoch 80/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.6172\n",
            "Epoch 81/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.6171\n",
            "Epoch 82/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.6171\n",
            "Epoch 83/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.6171\n",
            "Epoch 84/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.6170\n",
            "Epoch 85/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.6169\n",
            "Epoch 86/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.6168\n",
            "Epoch 87/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.6168\n",
            "Epoch 88/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.6167\n",
            "Epoch 89/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.6166\n",
            "Epoch 90/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.6166\n",
            "Epoch 91/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.6166\n",
            "Epoch 92/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.6164\n",
            "Epoch 93/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.6163\n",
            "Epoch 94/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.6163\n",
            "Epoch 95/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.6162\n",
            "Epoch 96/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6162\n",
            "Epoch 97/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6162\n",
            "Epoch 98/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.6161\n",
            "Epoch 99/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.6161\n",
            "Epoch 100/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.6160\n",
            "Acurácia no treino: 65.55\n",
            "Acurácia no teste: 34.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Início do código ###\n",
        "## Setando a seed\n",
        "np.random.seed(1)\n",
        "random.seed(1)\n",
        "\n",
        "### Executar uma rede de 1 camada oculta ###\n",
        "# Camadas da rede = [12288, 200, 1] \n",
        "\n",
        "# Definição do modelo\n",
        "model = Sequential()\n",
        "model.add(Dense(200, input_shape=(12288,), activation='relu', name='CamadaOculta', kernel_initializer=initializers.RandomNormal(mean=0., stddev=1.)))\n",
        "model.add(Dense(1, activation='sigmoid', name='CamadaClassificacao'))\n",
        "\n",
        "# Compilando o modelo\n",
        "model.compile(loss='binary_crossentropy', optimizer='adadelta')\n",
        "\n",
        "# Imprimindo a arquitetura da rede proposta\n",
        "model.summary()\n",
        "\n",
        "# Treinando o modelo\n",
        "model.fit(treino_x, treino_y.reshape(-1), epochs=100)\n",
        "### Fim do código ###\n",
        "\n",
        "## Predição da rede\n",
        "print(f'Acurácia no treino: {accuracy_score(treino_y.reshape(-1), np.round(model.predict(treino_x))) * 100:.2f}')\n",
        "print(f'Acurácia no teste: {accuracy_score(teste_y.reshape(-1), np.round(model.predict(teste_x))) * 100:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4CeVdIWCIMD",
        "outputId": "7d8afddb-1c81-4e1f-d775-4f0e9fd85657"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_36\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "CamadaOculta (Dense)         (None, 200)               2457800   \n",
            "_________________________________________________________________\n",
            "CamadaClassificacao (Dense)  (None, 1)                 201       \n",
            "=================================================================\n",
            "Total params: 2,458,001\n",
            "Trainable params: 2,458,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "7/7 [==============================] - 1s 35ms/step - loss: 5150.7856\n",
            "Epoch 2/100\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 5120.8037\n",
            "Epoch 3/100\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 5090.1641\n",
            "Epoch 4/100\n",
            "7/7 [==============================] - 0s 51ms/step - loss: 5058.9863\n",
            "Epoch 5/100\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 5027.8867\n",
            "Epoch 6/100\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 4995.3882\n",
            "Epoch 7/100\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 4964.7349\n",
            "Epoch 8/100\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 4932.2085\n",
            "Epoch 9/100\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 4900.4663\n",
            "Epoch 10/100\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 4868.7061\n",
            "Epoch 11/100\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 4836.0679\n",
            "Epoch 12/100\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 4804.9102\n",
            "Epoch 13/100\n",
            "7/7 [==============================] - 0s 33ms/step - loss: 4775.3906\n",
            "Epoch 14/100\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 4746.4248\n",
            "Epoch 15/100\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 4717.2979\n",
            "Epoch 16/100\n",
            "7/7 [==============================] - 0s 34ms/step - loss: 4687.7441\n",
            "Epoch 17/100\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 4656.8530\n",
            "Epoch 18/100\n",
            "7/7 [==============================] - 0s 33ms/step - loss: 4627.0557\n",
            "Epoch 19/100\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 4597.9653\n",
            "Epoch 20/100\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 4567.3833\n",
            "Epoch 21/100\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 4538.6118\n",
            "Epoch 22/100\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 4509.8574\n",
            "Epoch 23/100\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 4481.9834\n",
            "Epoch 24/100\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 4452.9829\n",
            "Epoch 25/100\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 4423.6348\n",
            "Epoch 26/100\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 4395.1792\n",
            "Epoch 27/100\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 4367.0474\n",
            "Epoch 28/100\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 4338.4536\n",
            "Epoch 29/100\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 4310.1772\n",
            "Epoch 30/100\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 4282.1245\n",
            "Epoch 31/100\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 4255.0972\n",
            "Epoch 32/100\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 4227.7905\n",
            "Epoch 33/100\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 4200.6978\n",
            "Epoch 34/100\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 4173.8438\n",
            "Epoch 35/100\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 4146.7412\n",
            "Epoch 36/100\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 4120.9009\n",
            "Epoch 37/100\n",
            "7/7 [==============================] - 0s 34ms/step - loss: 4094.0520\n",
            "Epoch 38/100\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 4067.2366\n",
            "Epoch 39/100\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 4040.4158\n",
            "Epoch 40/100\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 4013.3809\n",
            "Epoch 41/100\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 3987.0918\n",
            "Epoch 42/100\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 3960.7048\n",
            "Epoch 43/100\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 3934.0369\n",
            "Epoch 44/100\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 3905.7336\n",
            "Epoch 45/100\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 3878.3894\n",
            "Epoch 46/100\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 3850.1125\n",
            "Epoch 47/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 3822.3433\n",
            "Epoch 48/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 3795.4299\n",
            "Epoch 49/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 3768.8523\n",
            "Epoch 50/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 3740.7556\n",
            "Epoch 51/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 3713.0649\n",
            "Epoch 52/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 3685.5269\n",
            "Epoch 53/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 3658.0464\n",
            "Epoch 54/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 3631.3767\n",
            "Epoch 55/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 3604.9551\n",
            "Epoch 56/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 3578.7698\n",
            "Epoch 57/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 3552.4082\n",
            "Epoch 58/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 3526.1946\n",
            "Epoch 59/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 3500.1133\n",
            "Epoch 60/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 3473.3020\n",
            "Epoch 61/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 3446.9722\n",
            "Epoch 62/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 3420.4875\n",
            "Epoch 63/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 3394.3533\n",
            "Epoch 64/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 3368.8262\n",
            "Epoch 65/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 3344.4412\n",
            "Epoch 66/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 3320.3474\n",
            "Epoch 67/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 3296.2092\n",
            "Epoch 68/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 3273.0593\n",
            "Epoch 69/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 3247.9829\n",
            "Epoch 70/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 3223.1519\n",
            "Epoch 71/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 3198.6094\n",
            "Epoch 72/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 3173.4636\n",
            "Epoch 73/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 3151.1428\n",
            "Epoch 74/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 3130.5889\n",
            "Epoch 75/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 3108.9844\n",
            "Epoch 76/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 3085.6809\n",
            "Epoch 77/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 3064.0159\n",
            "Epoch 78/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 3043.0417\n",
            "Epoch 79/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 3024.2070\n",
            "Epoch 80/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 3005.1292\n",
            "Epoch 81/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 2986.8103\n",
            "Epoch 82/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 2966.0745\n",
            "Epoch 83/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 2945.2412\n",
            "Epoch 84/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 2926.8008\n",
            "Epoch 85/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 2908.7827\n",
            "Epoch 86/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 2891.3220\n",
            "Epoch 87/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 2873.6104\n",
            "Epoch 88/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 2857.2451\n",
            "Epoch 89/100\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 2841.6704\n",
            "Epoch 90/100\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 2823.5933\n",
            "Epoch 91/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 2806.6956\n",
            "Epoch 92/100\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 2790.2512\n",
            "Epoch 93/100\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 2774.4099\n",
            "Epoch 94/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 2758.3894\n",
            "Epoch 95/100\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 2742.2302\n",
            "Epoch 96/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 2727.5994\n",
            "Epoch 97/100\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 2713.4397\n",
            "Epoch 98/100\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 2698.2212\n",
            "Epoch 99/100\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 2684.6353\n",
            "Epoch 100/100\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 2671.1672\n",
            "Acurácia no treino: 58.37\n",
            "Acurácia no teste: 34.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Início do código ###\n",
        "## Setando a seed\n",
        "np.random.seed(1)\n",
        "random.seed(1)\n",
        "\n",
        "### Executar uma rede de 1 camada oculta ###\n",
        "# Camadas da rede = [12288, 200, 1] \n",
        "\n",
        "# Definição do modelo\n",
        "model = Sequential()\n",
        "model.add(Dense(200, input_shape=(12288,), activation='relu', name='CamadaOculta', kernel_initializer=initializers.RandomNormal(mean=0., stddev=1.)))\n",
        "model.add(Dense(1, activation='sigmoid', name='CamadaClassificacao'))\n",
        "\n",
        "# Compilando o modelo\n",
        "model.compile(loss='binary_crossentropy', optimizer='RMSPROP')\n",
        "\n",
        "# Imprimindo a arquitetura da rede proposta\n",
        "model.summary()\n",
        "\n",
        "# Treinando o modelo\n",
        "model.fit(treino_x, treino_y.reshape(-1), epochs=100)\n",
        "### Fim do código ###\n",
        "\n",
        "## Predição da rede\n",
        "print(f'Acurácia no treino: {accuracy_score(treino_y.reshape(-1), np.round(model.predict(treino_x))) * 100:.2f}')\n",
        "print(f'Acurácia no teste: {accuracy_score(teste_y.reshape(-1), np.round(model.predict(teste_x))) * 100:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8fM3EiNCqtD",
        "outputId": "b5d19753-89f8-4870-d7ea-857aed3a69f7"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_38\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "CamadaOculta (Dense)         (None, 200)               2457800   \n",
            "_________________________________________________________________\n",
            "CamadaClassificacao (Dense)  (None, 1)                 201       \n",
            "=================================================================\n",
            "Total params: 2,458,001\n",
            "Trainable params: 2,458,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "7/7 [==============================] - 2s 57ms/step - loss: 4054.2173\n",
            "Epoch 2/100\n",
            "7/7 [==============================] - 0s 56ms/step - loss: 1864.2961\n",
            "Epoch 3/100\n",
            "7/7 [==============================] - 0s 59ms/step - loss: 2696.4651\n",
            "Epoch 4/100\n",
            "7/7 [==============================] - 0s 56ms/step - loss: 1865.5386\n",
            "Epoch 5/100\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 2217.2871\n",
            "Epoch 6/100\n",
            "7/7 [==============================] - 0s 58ms/step - loss: 1321.0811\n",
            "Epoch 7/100\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 1139.0409\n",
            "Epoch 8/100\n",
            "7/7 [==============================] - 0s 50ms/step - loss: 1497.2927\n",
            "Epoch 9/100\n",
            "7/7 [==============================] - 0s 50ms/step - loss: 1214.1840\n",
            "Epoch 10/100\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 596.2684\n",
            "Epoch 11/100\n",
            "7/7 [==============================] - 0s 53ms/step - loss: 1877.8525\n",
            "Epoch 12/100\n",
            "7/7 [==============================] - 0s 54ms/step - loss: 1024.4708\n",
            "Epoch 13/100\n",
            "7/7 [==============================] - 1s 79ms/step - loss: 1481.7958\n",
            "Epoch 14/100\n",
            "7/7 [==============================] - 1s 70ms/step - loss: 897.0052\n",
            "Epoch 15/100\n",
            "7/7 [==============================] - 0s 59ms/step - loss: 902.1244\n",
            "Epoch 16/100\n",
            "7/7 [==============================] - 0s 59ms/step - loss: 768.0581\n",
            "Epoch 17/100\n",
            "7/7 [==============================] - 0s 57ms/step - loss: 1528.8011\n",
            "Epoch 18/100\n",
            "7/7 [==============================] - 0s 64ms/step - loss: 222.7047\n",
            "Epoch 19/100\n",
            "7/7 [==============================] - 0s 50ms/step - loss: 1065.8875\n",
            "Epoch 20/100\n",
            "7/7 [==============================] - 0s 65ms/step - loss: 980.9712\n",
            "Epoch 21/100\n",
            "7/7 [==============================] - 0s 50ms/step - loss: 350.7104\n",
            "Epoch 22/100\n",
            "7/7 [==============================] - 0s 60ms/step - loss: 1349.0385\n",
            "Epoch 23/100\n",
            "7/7 [==============================] - 0s 61ms/step - loss: 621.6638\n",
            "Epoch 24/100\n",
            "7/7 [==============================] - 0s 67ms/step - loss: 918.4906\n",
            "Epoch 25/100\n",
            "7/7 [==============================] - 0s 44ms/step - loss: 623.2444\n",
            "Epoch 26/100\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 55.0067\n",
            "Epoch 27/100\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 894.4382\n",
            "Epoch 28/100\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 555.0354\n",
            "Epoch 29/100\n",
            "7/7 [==============================] - 0s 44ms/step - loss: 404.8937\n",
            "Epoch 30/100\n",
            "7/7 [==============================] - 0s 43ms/step - loss: 840.3461\n",
            "Epoch 31/100\n",
            "7/7 [==============================] - 0s 49ms/step - loss: 115.7846\n",
            "Epoch 32/100\n",
            "7/7 [==============================] - 0s 55ms/step - loss: 441.4933\n",
            "Epoch 33/100\n",
            "7/7 [==============================] - 0s 50ms/step - loss: 38.6307\n",
            "Epoch 34/100\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 1118.6970\n",
            "Epoch 35/100\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 28.5537\n",
            "Epoch 36/100\n",
            "7/7 [==============================] - 0s 42ms/step - loss: 1041.6102\n",
            "Epoch 37/100\n",
            "7/7 [==============================] - 0s 43ms/step - loss: 498.6091\n",
            "Epoch 38/100\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 37.8627\n",
            "Epoch 39/100\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 762.0632\n",
            "Epoch 40/100\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 119.5714\n",
            "Epoch 41/100\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 30.9665\n",
            "Epoch 42/100\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 1096.0492\n",
            "Epoch 43/100\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 7.2257\n",
            "Epoch 44/100\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 233.6940\n",
            "Epoch 45/100\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 265.9740\n",
            "Epoch 46/100\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 77.6397\n",
            "Epoch 47/100\n",
            "7/7 [==============================] - 0s 49ms/step - loss: 943.8793\n",
            "Epoch 48/100\n",
            "7/7 [==============================] - 0s 50ms/step - loss: 145.1053\n",
            "Epoch 49/100\n",
            "7/7 [==============================] - 0s 51ms/step - loss: 2.7033\n",
            "Epoch 50/100\n",
            "7/7 [==============================] - 0s 43ms/step - loss: 0.0000e+00\n",
            "Epoch 51/100\n",
            "7/7 [==============================] - 0s 57ms/step - loss: 0.0000e+00\n",
            "Epoch 52/100\n",
            "7/7 [==============================] - 0s 43ms/step - loss: 0.0000e+00\n",
            "Epoch 53/100\n",
            "7/7 [==============================] - 0s 44ms/step - loss: 0.0000e+00\n",
            "Epoch 54/100\n",
            "7/7 [==============================] - 0s 66ms/step - loss: 0.0000e+00\n",
            "Epoch 55/100\n",
            "7/7 [==============================] - 0s 56ms/step - loss: 0.0000e+00\n",
            "Epoch 56/100\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0000e+00\n",
            "Epoch 57/100\n",
            "7/7 [==============================] - 0s 72ms/step - loss: 0.0000e+00\n",
            "Epoch 58/100\n",
            "7/7 [==============================] - 0s 64ms/step - loss: 0.0000e+00\n",
            "Epoch 59/100\n",
            "7/7 [==============================] - 0s 60ms/step - loss: 0.0000e+00\n",
            "Epoch 60/100\n",
            "7/7 [==============================] - 0s 67ms/step - loss: 0.0000e+00\n",
            "Epoch 61/100\n",
            "7/7 [==============================] - 1s 76ms/step - loss: 0.0000e+00\n",
            "Epoch 62/100\n",
            "7/7 [==============================] - 0s 73ms/step - loss: 0.0000e+00\n",
            "Epoch 63/100\n",
            "7/7 [==============================] - 0s 67ms/step - loss: 0.0000e+00\n",
            "Epoch 64/100\n",
            "7/7 [==============================] - 0s 67ms/step - loss: 0.0000e+00\n",
            "Epoch 65/100\n",
            "7/7 [==============================] - 0s 49ms/step - loss: 0.0000e+00\n",
            "Epoch 66/100\n",
            "7/7 [==============================] - 0s 56ms/step - loss: 0.0000e+00\n",
            "Epoch 67/100\n",
            "7/7 [==============================] - 0s 59ms/step - loss: 0.0000e+00\n",
            "Epoch 68/100\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.0000e+00\n",
            "Epoch 69/100\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.0000e+00\n",
            "Epoch 70/100\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.0000e+00\n",
            "Epoch 71/100\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.0000e+00\n",
            "Epoch 72/100\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.0000e+00\n",
            "Epoch 73/100\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.0000e+00\n",
            "Epoch 74/100\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.0000e+00\n",
            "Epoch 75/100\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.0000e+00\n",
            "Epoch 76/100\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.0000e+00\n",
            "Epoch 77/100\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.0000e+00\n",
            "Epoch 78/100\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.0000e+00\n",
            "Epoch 79/100\n",
            "7/7 [==============================] - 0s 33ms/step - loss: 0.0000e+00\n",
            "Epoch 80/100\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 0.0000e+00\n",
            "Epoch 81/100\n",
            "7/7 [==============================] - 0s 34ms/step - loss: 0.0000e+00\n",
            "Epoch 82/100\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 0.0000e+00\n",
            "Epoch 83/100\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 0.0000e+00\n",
            "Epoch 84/100\n",
            "7/7 [==============================] - 0s 34ms/step - loss: 0.0000e+00\n",
            "Epoch 85/100\n",
            "7/7 [==============================] - 0s 34ms/step - loss: 0.0000e+00\n",
            "Epoch 86/100\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.0000e+00\n",
            "Epoch 87/100\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.0000e+00\n",
            "Epoch 88/100\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 0.0000e+00\n",
            "Epoch 89/100\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.0000e+00\n",
            "Epoch 90/100\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.0000e+00\n",
            "Epoch 91/100\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.0000e+00\n",
            "Epoch 92/100\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.0000e+00\n",
            "Epoch 93/100\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.0000e+00\n",
            "Epoch 94/100\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.0000e+00\n",
            "Epoch 95/100\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.0000e+00\n",
            "Epoch 96/100\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.0000e+00\n",
            "Epoch 97/100\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.0000e+00\n",
            "Epoch 98/100\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.0000e+00\n",
            "Epoch 99/100\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.0000e+00\n",
            "Epoch 100/100\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.0000e+00\n",
            "Acurácia no treino: 100.00\n",
            "Acurácia no teste: 66.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Início do código ###\n",
        "## Setando a seed\n",
        "np.random.seed(1)\n",
        "random.seed(1)\n",
        "\n",
        "### Executar uma rede de 1 camada oculta ###\n",
        "# Camadas da rede = [12288, 200, 1] \n",
        "\n",
        "# Definição do modelo\n",
        "model = Sequential()\n",
        "model.add(Dense(200, input_shape=(12288,), activation='gelu', name='CamadaOculta', kernel_initializer=initializers.RandomNormal(mean=0., stddev=1.)))\n",
        "model.add(Dense(1, activation='sigmoid', name='CamadaClassificacao'))\n",
        "\n",
        "# Compilando o modelo\n",
        "model.compile(loss='binary_crossentropy', optimizer='RMSPROP')\n",
        "\n",
        "# Imprimindo a arquitetura da rede proposta\n",
        "model.summary()\n",
        "\n",
        "# Treinando o modelo\n",
        "model.fit(treino_x, treino_y.reshape(-1), epochs=100)\n",
        "### Fim do código ###\n",
        "\n",
        "## Predição da rede\n",
        "print(f'Acurácia no treino: {accuracy_score(treino_y.reshape(-1), np.round(model.predict(treino_x))) * 100:.2f}')\n",
        "print(f'Acurácia no teste: {accuracy_score(teste_y.reshape(-1), np.round(model.predict(teste_x))) * 100:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDql6gRJC_dM",
        "outputId": "5dda7da3-2105-4c77-b953-3dc753fe003f"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_39\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "CamadaOculta (Dense)         (None, 200)               2457800   \n",
            "_________________________________________________________________\n",
            "CamadaClassificacao (Dense)  (None, 1)                 201       \n",
            "=================================================================\n",
            "Total params: 2,458,001\n",
            "Trainable params: 2,458,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "7/7 [==============================] - 1s 46ms/step - loss: 5737.9663\n",
            "Epoch 2/100\n",
            "7/7 [==============================] - 0s 54ms/step - loss: 2765.4031\n",
            "Epoch 3/100\n",
            "7/7 [==============================] - 0s 54ms/step - loss: 2231.6526\n",
            "Epoch 4/100\n",
            "7/7 [==============================] - 0s 56ms/step - loss: 1640.0140\n",
            "Epoch 5/100\n",
            "7/7 [==============================] - 0s 49ms/step - loss: 2217.1462\n",
            "Epoch 6/100\n",
            "7/7 [==============================] - 0s 58ms/step - loss: 2310.2590\n",
            "Epoch 7/100\n",
            "7/7 [==============================] - 0s 42ms/step - loss: 1077.2880\n",
            "Epoch 8/100\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 1708.5029\n",
            "Epoch 9/100\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 1184.1528\n",
            "Epoch 10/100\n",
            "7/7 [==============================] - 0s 54ms/step - loss: 1575.5142\n",
            "Epoch 11/100\n",
            "7/7 [==============================] - 0s 58ms/step - loss: 672.7892\n",
            "Epoch 12/100\n",
            "7/7 [==============================] - 0s 57ms/step - loss: 963.4060\n",
            "Epoch 13/100\n",
            "7/7 [==============================] - 0s 57ms/step - loss: 534.7653\n",
            "Epoch 14/100\n",
            "7/7 [==============================] - 0s 51ms/step - loss: 1900.6803\n",
            "Epoch 15/100\n",
            "7/7 [==============================] - 0s 60ms/step - loss: 825.5748\n",
            "Epoch 16/100\n",
            "7/7 [==============================] - 0s 52ms/step - loss: 1150.9854\n",
            "Epoch 17/100\n",
            "7/7 [==============================] - 0s 53ms/step - loss: 864.4625\n",
            "Epoch 18/100\n",
            "7/7 [==============================] - 0s 58ms/step - loss: 912.5363\n",
            "Epoch 19/100\n",
            "7/7 [==============================] - 0s 58ms/step - loss: 750.0844\n",
            "Epoch 20/100\n",
            "7/7 [==============================] - 0s 49ms/step - loss: 671.9893\n",
            "Epoch 21/100\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 414.4031\n",
            "Epoch 22/100\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 202.2618\n",
            "Epoch 23/100\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 1069.3558\n",
            "Epoch 24/100\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 518.3150\n",
            "Epoch 25/100\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 844.9096\n",
            "Epoch 26/100\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 390.0580\n",
            "Epoch 27/100\n",
            "7/7 [==============================] - 0s 42ms/step - loss: 745.7590\n",
            "Epoch 28/100\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 206.9407\n",
            "Epoch 29/100\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 928.3510\n",
            "Epoch 30/100\n",
            "7/7 [==============================] - 0s 42ms/step - loss: 493.9917\n",
            "Epoch 31/100\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 453.5616\n",
            "Epoch 32/100\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 54.6309\n",
            "Epoch 33/100\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 816.1429\n",
            "Epoch 34/100\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 30.7136\n",
            "Epoch 35/100\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 656.0785\n",
            "Epoch 36/100\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 48.8846\n",
            "Epoch 37/100\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 22.0516\n",
            "Epoch 38/100\n",
            "7/7 [==============================] - 1s 78ms/step - loss: 574.5815\n",
            "Epoch 39/100\n",
            "7/7 [==============================] - 0s 59ms/step - loss: 41.9620\n",
            "Epoch 40/100\n",
            "7/7 [==============================] - 0s 53ms/step - loss: 891.3387\n",
            "Epoch 41/100\n",
            "7/7 [==============================] - 0s 33ms/step - loss: 330.7294\n",
            "Epoch 42/100\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 253.7081\n",
            "Epoch 43/100\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 1129.3330\n",
            "Epoch 44/100\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 72.2019\n",
            "Epoch 45/100\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.0000e+00\n",
            "Epoch 46/100\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.0000e+00\n",
            "Epoch 47/100\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.0000e+00\n",
            "Epoch 48/100\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.0000e+00\n",
            "Epoch 49/100\n",
            "7/7 [==============================] - 0s 42ms/step - loss: 0.0000e+00\n",
            "Epoch 50/100\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.0000e+00\n",
            "Epoch 51/100\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.0000e+00\n",
            "Epoch 52/100\n",
            "7/7 [==============================] - 0s 60ms/step - loss: 0.0000e+00\n",
            "Epoch 53/100\n",
            "7/7 [==============================] - 0s 56ms/step - loss: 0.0000e+00\n",
            "Epoch 54/100\n",
            "7/7 [==============================] - 0s 57ms/step - loss: 0.0000e+00\n",
            "Epoch 55/100\n",
            "7/7 [==============================] - 0s 56ms/step - loss: 0.0000e+00\n",
            "Epoch 56/100\n",
            "7/7 [==============================] - 0s 53ms/step - loss: 0.0000e+00\n",
            "Epoch 57/100\n",
            "7/7 [==============================] - 0s 44ms/step - loss: 0.0000e+00\n",
            "Epoch 58/100\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.0000e+00\n",
            "Epoch 59/100\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.0000e+00\n",
            "Epoch 60/100\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.0000e+00\n",
            "Epoch 61/100\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.0000e+00\n",
            "Epoch 62/100\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.0000e+00\n",
            "Epoch 63/100\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.0000e+00\n",
            "Epoch 64/100\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.0000e+00\n",
            "Epoch 65/100\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.0000e+00\n",
            "Epoch 66/100\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.0000e+00\n",
            "Epoch 67/100\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.0000e+00\n",
            "Epoch 68/100\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.0000e+00\n",
            "Epoch 69/100\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.0000e+00\n",
            "Epoch 70/100\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.0000e+00\n",
            "Epoch 71/100\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.0000e+00\n",
            "Epoch 72/100\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.0000e+00\n",
            "Epoch 73/100\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.0000e+00\n",
            "Epoch 74/100\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.0000e+00\n",
            "Epoch 75/100\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.0000e+00\n",
            "Epoch 76/100\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.0000e+00\n",
            "Epoch 77/100\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.0000e+00\n",
            "Epoch 78/100\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.0000e+00\n",
            "Epoch 79/100\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.0000e+00\n",
            "Epoch 80/100\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.0000e+00\n",
            "Epoch 81/100\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.0000e+00\n",
            "Epoch 82/100\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.0000e+00\n",
            "Epoch 83/100\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.0000e+00\n",
            "Epoch 84/100\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 0.0000e+00\n",
            "Epoch 85/100\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.0000e+00\n",
            "Epoch 86/100\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.0000e+00\n",
            "Epoch 87/100\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.0000e+00\n",
            "Epoch 88/100\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.0000e+00\n",
            "Epoch 89/100\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.0000e+00\n",
            "Epoch 90/100\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.0000e+00\n",
            "Epoch 91/100\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.0000e+00\n",
            "Epoch 92/100\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.0000e+00\n",
            "Epoch 93/100\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.0000e+00\n",
            "Epoch 94/100\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.0000e+00\n",
            "Epoch 95/100\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.0000e+00\n",
            "Epoch 96/100\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.0000e+00\n",
            "Epoch 97/100\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.0000e+00\n",
            "Epoch 98/100\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 0.0000e+00\n",
            "Epoch 99/100\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.0000e+00\n",
            "Epoch 100/100\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.0000e+00\n",
            "Acurácia no treino: 100.00\n",
            "Acurácia no teste: 66.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Início do código ###\n",
        "## Setando a seed\n",
        "np.random.seed(1)\n",
        "random.seed(1)\n",
        "\n",
        "### Executar uma rede de 1 camada oculta ###\n",
        "# Camadas da rede = [12288, 200, 1] \n",
        "\n",
        "# Definição do modelo\n",
        "model = Sequential()\n",
        "model.add(Dense(200, input_shape=(12288,), activation='gelu', name='CamadaOculta', kernel_initializer=initializers.RandomNormal(mean=0., stddev=1.)))\n",
        "model.add(Dense(1, activation='sigmoid', name='CamadaClassificacao'))\n",
        "\n",
        "# Compilando o modelo\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "\n",
        "# Imprimindo a arquitetura da rede proposta\n",
        "model.summary()\n",
        "\n",
        "# Treinando o modelo\n",
        "model.fit(treino_x, treino_y.reshape(-1), epochs=100)\n",
        "### Fim do código ###\n",
        "\n",
        "## Predição da rede\n",
        "print(f'Acurácia no treino: {accuracy_score(treino_y.reshape(-1), np.round(model.predict(treino_x))) * 100:.2f}')\n",
        "print(f'Acurácia no teste: {accuracy_score(teste_y.reshape(-1), np.round(model.predict(teste_x))) * 100:.2f}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inByi29iDVgL",
        "outputId": "62194c1a-f3b0-4565-b247-a85ceb59df76"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_42\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "CamadaOculta (Dense)         (None, 200)               2457800   \n",
            "_________________________________________________________________\n",
            "CamadaClassificacao (Dense)  (None, 1)                 201       \n",
            "=================================================================\n",
            "Total params: 2,458,001\n",
            "Trainable params: 2,458,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "7/7 [==============================] - 1s 29ms/step - loss: 2996.5029\n",
            "Epoch 2/100\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 1741.5472\n",
            "Epoch 3/100\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 1315.8313\n",
            "Epoch 4/100\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 880.3184\n",
            "Epoch 5/100\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 732.8141\n",
            "Epoch 6/100\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 473.6812\n",
            "Epoch 7/100\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 428.6912\n",
            "Epoch 8/100\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 401.0302\n",
            "Epoch 9/100\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 404.4957\n",
            "Epoch 10/100\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 364.8183\n",
            "Epoch 11/100\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 107.8579\n",
            "Epoch 12/100\n",
            "7/7 [==============================] - 0s 34ms/step - loss: 102.0912\n",
            "Epoch 13/100\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 36.8469\n",
            "Epoch 14/100\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 38.1487\n",
            "Epoch 15/100\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 20.3557\n",
            "Epoch 16/100\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 11.1307\n",
            "Epoch 17/100\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 5.8511\n",
            "Epoch 18/100\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 9.4418\n",
            "Epoch 19/100\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 9.2359\n",
            "Epoch 20/100\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 2.0137\n",
            "Epoch 21/100\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 3.1296\n",
            "Epoch 22/100\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 12.2996\n",
            "Epoch 23/100\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 18.2854\n",
            "Epoch 24/100\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 16.7159\n",
            "Epoch 25/100\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 3.6598\n",
            "Epoch 26/100\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 25.7289\n",
            "Epoch 27/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 31.2848\n",
            "Epoch 28/100\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 31.3797\n",
            "Epoch 29/100\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 1.2151\n",
            "Epoch 30/100\n",
            "7/7 [==============================] - 0s 34ms/step - loss: 19.4396\n",
            "Epoch 31/100\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 13.9381\n",
            "Epoch 32/100\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 19.7358\n",
            "Epoch 33/100\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 96.1280\n",
            "Epoch 34/100\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 206.1199\n",
            "Epoch 35/100\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 74.7817\n",
            "Epoch 36/100\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 73.4999\n",
            "Epoch 37/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 46.9110\n",
            "Epoch 38/100\n",
            "7/7 [==============================] - 0s 33ms/step - loss: 17.2339\n",
            "Epoch 39/100\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 8.4240\n",
            "Epoch 40/100\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 39.6805\n",
            "Epoch 41/100\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 118.6183\n",
            "Epoch 42/100\n",
            "7/7 [==============================] - 0s 33ms/step - loss: 89.6801\n",
            "Epoch 43/100\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 96.4220\n",
            "Epoch 44/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 78.1895\n",
            "Epoch 45/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 164.4048\n",
            "Epoch 46/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 50.1002\n",
            "Epoch 47/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 25.9579\n",
            "Epoch 48/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 7.3081\n",
            "Epoch 49/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 1.3358\n",
            "Epoch 50/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 12.3755\n",
            "Epoch 51/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 3.7371\n",
            "Epoch 52/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 6.0718\n",
            "Epoch 53/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 7.2831\n",
            "Epoch 54/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 12.5695\n",
            "Epoch 55/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 9.6430\n",
            "Epoch 56/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 4.6017\n",
            "Epoch 57/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.0000e+00\n",
            "Epoch 58/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 2.8578\n",
            "Epoch 59/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 7.1331\n",
            "Epoch 60/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0000e+00\n",
            "Epoch 61/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0000e+00\n",
            "Epoch 62/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0000e+00\n",
            "Epoch 63/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0350\n",
            "Epoch 64/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0000e+00\n",
            "Epoch 65/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0000e+00\n",
            "Epoch 66/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0000e+00\n",
            "Epoch 67/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0000e+00\n",
            "Epoch 68/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0000e+00\n",
            "Epoch 69/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0000e+00\n",
            "Epoch 70/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0000e+00\n",
            "Epoch 71/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0000e+00\n",
            "Epoch 72/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.0000e+00\n",
            "Epoch 73/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.0000e+00\n",
            "Epoch 74/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.0000e+00\n",
            "Epoch 75/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.0000e+00\n",
            "Epoch 76/100\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.0000e+00\n",
            "Epoch 77/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.0000e+00\n",
            "Epoch 78/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0000e+00\n",
            "Epoch 79/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0000e+00\n",
            "Epoch 80/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0000e+00\n",
            "Epoch 81/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0000e+00\n",
            "Epoch 82/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0000e+00\n",
            "Epoch 83/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0000e+00\n",
            "Epoch 84/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0000e+00\n",
            "Epoch 85/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.0000e+00\n",
            "Epoch 86/100\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 0.0000e+00\n",
            "Epoch 87/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.0000e+00\n",
            "Epoch 88/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.0000e+00\n",
            "Epoch 89/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.0000e+00\n",
            "Epoch 90/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.0000e+00\n",
            "Epoch 91/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.0000e+00\n",
            "Epoch 92/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.0000e+00\n",
            "Epoch 93/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0000e+00\n",
            "Epoch 94/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0000e+00\n",
            "Epoch 95/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0000e+00\n",
            "Epoch 96/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0000e+00\n",
            "Epoch 97/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0000e+00\n",
            "Epoch 98/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.0000e+00\n",
            "Epoch 99/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.0000e+00\n",
            "Epoch 100/100\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.0000e+00\n",
            "Acurácia no treino: 100.00\n",
            "Acurácia no teste: 56.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Início do código ###\n",
        "## Setando a seed\n",
        "np.random.seed(1)\n",
        "random.seed(1)\n",
        "\n",
        "### Executar uma rede de 1 camada oculta ###\n",
        "# Camadas da rede = [12288, 200, 1] \n",
        "\n",
        "# Definição do modelo\n",
        "model = Sequential()\n",
        "model.add(Dense(200, input_shape=(12288,), activation='relu', name='CamadaOculta'))\n",
        "model.add(Dense(1, activation='sigmoid', name='CamadaClassificacao'))\n",
        "\n",
        "# Compilando o modelo\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "\n",
        "# Imprimindo a arquitetura da rede proposta\n",
        "model.summary()\n",
        "\n",
        "# Treinando o modelo\n",
        "model.fit(treino_x, treino_y.reshape(-1), epochs=100)\n",
        "### Fim do código ###\n",
        "\n",
        "## Predição da rede\n",
        "print(f'Acurácia no treino: {accuracy_score(treino_y.reshape(-1), np.round(model.predict(treino_x))) * 100:.2f}')\n",
        "print(f'Acurácia no teste: {accuracy_score(teste_y.reshape(-1), np.round(model.predict(teste_x))) * 100:.2f}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rNvrB--DuLf",
        "outputId": "20c4e14c-73d4-4717-ee47-2da19138f92d"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_43\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "CamadaOculta (Dense)         (None, 200)               2457800   \n",
            "_________________________________________________________________\n",
            "CamadaClassificacao (Dense)  (None, 1)                 201       \n",
            "=================================================================\n",
            "Total params: 2,458,001\n",
            "Trainable params: 2,458,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "7/7 [==============================] - 1s 21ms/step - loss: 1899.5931\n",
            "Epoch 2/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 609.6093\n",
            "Epoch 3/100\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 267.2789\n",
            "Epoch 4/100\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 152.4326\n",
            "Epoch 5/100\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 110.7168\n",
            "Epoch 6/100\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 36.1824\n",
            "Epoch 7/100\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 46.9148\n",
            "Epoch 8/100\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 60.9487\n",
            "Epoch 9/100\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 33.9603\n",
            "Epoch 10/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 22.7876\n",
            "Epoch 11/100\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 13.9051\n",
            "Epoch 12/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 17.7887\n",
            "Epoch 13/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 27.3105\n",
            "Epoch 14/100\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 19.7043\n",
            "Epoch 15/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 12.6698\n",
            "Epoch 16/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 17.2494\n",
            "Epoch 17/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 13.4265\n",
            "Epoch 18/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 18.8268\n",
            "Epoch 19/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 4.0057\n",
            "Epoch 20/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 2.8827\n",
            "Epoch 21/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 2.0993\n",
            "Epoch 22/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 1.2552\n",
            "Epoch 23/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.6161\n",
            "Epoch 24/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 3.4919\n",
            "Epoch 25/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 2.6615\n",
            "Epoch 26/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 6.7579\n",
            "Epoch 27/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 7.1799\n",
            "Epoch 28/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 5.6805\n",
            "Epoch 29/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 3.1913\n",
            "Epoch 30/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 1.7209\n",
            "Epoch 31/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 1.8711\n",
            "Epoch 32/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 6.8410\n",
            "Epoch 33/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 5.1408\n",
            "Epoch 34/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 14.6293\n",
            "Epoch 35/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 7.1831\n",
            "Epoch 36/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 4.4758\n",
            "Epoch 37/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 3.6851\n",
            "Epoch 38/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 1.5657\n",
            "Epoch 39/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.5501\n",
            "Epoch 40/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.2107\n",
            "Epoch 41/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 2.8083\n",
            "Epoch 42/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 2.1791\n",
            "Epoch 43/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.3242\n",
            "Epoch 44/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.6412\n",
            "Epoch 45/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.2553\n",
            "Epoch 46/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.3250\n",
            "Epoch 47/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.1515\n",
            "Epoch 48/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 1.5060\n",
            "Epoch 49/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 31.2053\n",
            "Epoch 50/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 20.0441\n",
            "Epoch 51/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 7.9640\n",
            "Epoch 52/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 9.6129\n",
            "Epoch 53/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 11.8547\n",
            "Epoch 54/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 11.1653\n",
            "Epoch 55/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 2.8083\n",
            "Epoch 56/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 1.3576\n",
            "Epoch 57/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.1974\n",
            "Epoch 58/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.2250\n",
            "Epoch 59/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.2835\n",
            "Epoch 60/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.3691\n",
            "Epoch 61/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.9783\n",
            "Epoch 62/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 1.9819\n",
            "Epoch 63/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 3.7513\n",
            "Epoch 64/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 7.9736\n",
            "Epoch 65/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 1.4680\n",
            "Epoch 66/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.9586\n",
            "Epoch 67/100\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.3983\n",
            "Epoch 68/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.1173\n",
            "Epoch 69/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 1.1829\n",
            "Epoch 70/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.6866\n",
            "Epoch 71/100\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.0027\n",
            "Epoch 72/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.3031\n",
            "Epoch 73/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.3477\n",
            "Epoch 74/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.5766\n",
            "Epoch 75/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.5231\n",
            "Epoch 76/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 4.7939\n",
            "Epoch 77/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 9.1244\n",
            "Epoch 78/100\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 4.1251\n",
            "Epoch 79/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 1.9118\n",
            "Epoch 80/100\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 2.5588\n",
            "Epoch 81/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.7820\n",
            "Epoch 82/100\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 3.8811\n",
            "Epoch 83/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 1.1483\n",
            "Epoch 84/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 1.0291\n",
            "Epoch 85/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 2.8293\n",
            "Epoch 86/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 5.1347\n",
            "Epoch 87/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.9128\n",
            "Epoch 88/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 1.6114\n",
            "Epoch 89/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.5172\n",
            "Epoch 90/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0686\n",
            "Epoch 91/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.1486\n",
            "Epoch 92/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 5.8473e-11\n",
            "Epoch 93/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0105\n",
            "Epoch 94/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0337\n",
            "Epoch 95/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0092\n",
            "Epoch 96/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.1227\n",
            "Epoch 97/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.2604\n",
            "Epoch 98/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.1447\n",
            "Epoch 99/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.0578\n",
            "Epoch 100/100\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 2.3638e-09\n",
            "Acurácia no treino: 100.00\n",
            "Acurácia no teste: 74.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **ToDo:** Analisando redes treinadas (5pt)"
      ],
      "metadata": {
        "id": "HL0n8qNxyA2C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Qual combinação rendeu o melhor resultado? Tente explicar o por que.\n",
        "\n",
        "` A melhor combinação para um rede de 1 camada oculta com 200 neurônios foi a rede que utilizou: inicialização de pesos uniformes, a função relu como função de ativação e o algoritmo de otimização adam. Isso acontece porque a função ReLU não ativa todos os neurônios ao mesmo tempo, isso significa que, ao mesmo tempo, apenas alguns neurônios são ativados, tornando a rede esparsa e eficiente e fácil para a computação. Com a inicialização do pesos de maneira uniforme evita-se o problema com a saturação dos neurônios. Já o uso do Adam como otimizador garante eficiência ao trabalhar com problemas envolvendo muitos dados ou parâmetros, como neste caso.`"
      ],
      "metadata": {
        "id": "3_V-NodmyERd"
      }
    }
  ]
}