{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 5 - BCC406\n",
        "\n",
        "## REDES NEURAIS E APRENDIZAGEM EM PROFUNDIDADE\n",
        "\n",
        "## Redes de Convolução (CNN)\n",
        "\n",
        "### Prof. Eduardo e Prof. Pedro\n",
        "\n",
        "Objetivos:\n",
        "\n",
        "- Uso de modelos para biometria.\n",
        "- Uso de modelos pré-treinados para biometria.\n",
        "- Notebook baseado em tensorflow e Keras.\n",
        "\n",
        "Data da entrega : 23/09 \n",
        "\n",
        "- Execute todo notebook e salve tudo em um PDF **nomeado** como \"NomeSobrenome-LabX.pdf\"\n",
        "- Envie o PDF via google [FORM](https://forms.gle/4k8bjrzH3KYzRWMg9)\n"
      ],
      "metadata": {
        "id": "GtOtsitDzLuh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6I8kas8Ib9l"
      },
      "source": [
        "# Biometria"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Biometria nada mais é do que uma medida biológica, do grego *bios* - vida, e *metricos* - medida. O conceito de biometria surgiu em 1858, contudo o seu uso como tecnologia de segurança data de 1972. Essa abordagem sobrepuja o sistema de login-senha, pois se baseia em características únicas do indivíduo e que são difíceis de se copiar.\n",
        "\n",
        "É possível realizar o reconhecimento de um indivíduo por meio de técnicas computacionais em conjunto com alguma modalidade biométrica. Para este processo dá-se o nome de Sistemas Biométricos. Várias partes do corpo humano podem ser usadas para a realização do reconhecimento, como, por exemplo: face, íris e a impressão digital, sendo esta considerada como a primeira biometria usada. Ela não se restringe somente a características físicas, mas também comportamentais (forma de andar) ou a união de ambas.\n",
        "\n",
        "A prática de hoje envolve a biometria (classificação) de uma base de olhos. Você deve desenvolver uma rede neural para resolver o problema. Você pode propor uma nova rede ou fazer *transfer learning* de uma rede existente.\n",
        "\n",
        "Os resultados devem ser postados nesse [Google Sheets](https://docs.google.com/spreadsheets/d/1IhgAz-J-8tGxGwKhGneVsnfg87lX1bpdTwefjzosB1Y/edit?usp=sharing). O aluno com maior **acurácia** terá um ponto extra. Resultados distantes do melhor resultado serão penalizados. O melhor resultado será comparado com um *baseline*. \n",
        "\n",
        "A base de dados está disponível no Drive da disciplina na pasta de *datasets/eye*. Dentro da pasta, há uma pasta *test* e *train*. A primeira são as imagens que devem ser usadas para reportar os resultados no Google Sheets e a segunda usada para treinar o modelo. Dentro de cada uma das duas pastas, há outras 50 pastas (labels), cada uma com imagens de cada classe."
      ],
      "metadata": {
        "id": "P27P48S-wCZM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Código"
      ],
      "metadata": {
        "id": "b8CZ83royzft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importações\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.metrics import classification_report\n",
        "from keras.layers import Conv2D, MaxPool2D, Dropout\n",
        "from tensorflow.keras.applications import ResNet152V2, MobileNet\n",
        "from keras.applications.densenet import DenseNet201\n"
      ],
      "metadata": {
        "id": "UEhKKj7fyt6E"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ligar ao Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "jtW1aKn7-SS0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac9001e2-debe-4943-d13b-9a2b64bf040f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ler base de dados\n",
        "data_shape = (224, 224)\n",
        "\n",
        "root_dir = '/content/drive/My Drive/eyes/train/'\n",
        "files = [os.path.join(path, name) for path, subdirs, files in os.walk(root_dir) for name in files]\n",
        "train_x = np.asarray([cv2.resize(cv2.imread(name, cv2.IMREAD_COLOR), data_shape, interpolation=cv2.INTER_AREA) for name in files])\n",
        "train_y = np.asarray([int(name[-10:-7]) for name in files])\n",
        "\n",
        "root_dir = '/content/drive/My Drive/eyes/test/'\n",
        "files = [os.path.join(path, name) for path, subdirs, files in os.walk(root_dir) for name in files]\n",
        "test_x = np.asarray([cv2.resize(cv2.imread(name, cv2.IMREAD_COLOR), data_shape, interpolation=cv2.INTER_AREA) for name in files])\n",
        "test_y = np.asarray([int(name[-10:-7]) for name in files])"
      ],
      "metadata": {
        "id": "vRmEVlx69N50"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tamanho da entrada e número de classes\n",
        "input_size = (train_x.shape[1], train_x.shape[2],train_x.shape[3])\n",
        "n_classes = 51"
      ],
      "metadata": {
        "id": "B-RD07pR_Met"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Montar Modelo 1\n",
        "\n",
        "model1 = models.Sequential()\n",
        "\n",
        "model1.add(layers.InputLayer(input_shape=input_size)) \n",
        "model1.add(MobileNet(include_top=False, input_shape=input_size))\n",
        "\n",
        "model1.add(Conv2D(256, 2, 2, padding=\"same\", activation=\"relu\"))\n",
        "model1.add(Dropout(0.05))\n",
        "model1.add(Conv2D(4,2,2))\n",
        "\n",
        "\"\"\"model1.add(Conv2D(512, 3, padding=\"same\", activation=\"relu\"))\n",
        "model1.add(Conv2D(512, 3, padding=\"same\", activation=\"relu\"))\n",
        "model1.add(Conv2D(256, 3, 2, padding=\"same\", activation=\"relu\"))\n",
        "model1.add(Conv2D(256, 2, 2, padding=\"same\", activation=\"relu\"))\n",
        "model1.add(Dropout(0.05))\n",
        "model1.add(Conv2D(4,2,2))\"\"\"\n",
        "\n",
        "model1.add(layers.Flatten())\n",
        "\n",
        "model1.add(layers.Dense(n_classes, activation='softmax', name='CamadaClassificacao'))\n",
        "                       \n",
        "model1.summary()\n",
        "\n",
        "# Compilar\n",
        "model1.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "#Treinar\n",
        "model1.fit(train_x, train_y, epochs=70)\n",
        "\n",
        "#Obter Resultados\n",
        "y_pred = model1.predict(test_x, verbose=1)\n",
        "y_pred_bool = np.argmax(y_pred, axis=1)\n",
        "\n",
        "print(list(y_pred_bool))\n",
        "print(list(test_y.reshape(-1)))\n",
        "\n",
        "print(classification_report(test_y.reshape(-1), y_pred_bool))\n",
        "#print(\"\\n\\nAcurácia: \", sum([ 1 for i in zip(y_pred_bool, test_y.reshape(-1)) if i[0] == i[1]])/test_y.shape[0] ,\"\\n\\n\")"
      ],
      "metadata": {
        "id": "QhvuP4af-wnk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40d3c29b-c107-4efa-eafc-9f88544f97bf"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " mobilenet_1.00_224 (Functio  (None, 7, 7, 1024)       3228864   \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 4, 4, 256)         1048832   \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 2, 2, 4)           4100      \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 16)                0         \n",
            "                                                                 \n",
            " CamadaClassificacao (Dense)  (None, 51)               867       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,282,663\n",
            "Trainable params: 4,260,775\n",
            "Non-trainable params: 21,888\n",
            "_________________________________________________________________\n",
            "Epoch 1/70\n",
            "6/6 [==============================] - 3s 162ms/step - loss: 4.1713 - accuracy: 0.2118\n",
            "Epoch 2/70\n",
            "6/6 [==============================] - 1s 159ms/step - loss: 0.7536 - accuracy: 0.8000\n",
            "Epoch 3/70\n",
            "6/6 [==============================] - 1s 159ms/step - loss: 0.1538 - accuracy: 0.9706\n",
            "Epoch 4/70\n",
            "6/6 [==============================] - 1s 159ms/step - loss: 0.0568 - accuracy: 0.9824\n",
            "Epoch 5/70\n",
            "6/6 [==============================] - 1s 160ms/step - loss: 0.0343 - accuracy: 0.9824\n",
            "Epoch 6/70\n",
            "6/6 [==============================] - 1s 160ms/step - loss: 0.0091 - accuracy: 1.0000\n",
            "Epoch 7/70\n",
            "6/6 [==============================] - 1s 161ms/step - loss: 0.0610 - accuracy: 0.9824\n",
            "Epoch 8/70\n",
            "6/6 [==============================] - 1s 162ms/step - loss: 0.0090 - accuracy: 1.0000\n",
            "Epoch 9/70\n",
            "6/6 [==============================] - 1s 160ms/step - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 10/70\n",
            "6/6 [==============================] - 1s 159ms/step - loss: 0.0030 - accuracy: 1.0000\n",
            "Epoch 11/70\n",
            "6/6 [==============================] - 1s 162ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 12/70\n",
            "6/6 [==============================] - 1s 158ms/step - loss: 5.9821e-04 - accuracy: 1.0000\n",
            "Epoch 13/70\n",
            "6/6 [==============================] - 1s 159ms/step - loss: 5.2100e-04 - accuracy: 1.0000\n",
            "Epoch 14/70\n",
            "6/6 [==============================] - 1s 156ms/step - loss: 4.6537e-04 - accuracy: 1.0000\n",
            "Epoch 15/70\n",
            "6/6 [==============================] - 1s 164ms/step - loss: 6.1284e-04 - accuracy: 1.0000\n",
            "Epoch 16/70\n",
            "6/6 [==============================] - 1s 159ms/step - loss: 3.6607e-04 - accuracy: 1.0000\n",
            "Epoch 17/70\n",
            "6/6 [==============================] - 1s 162ms/step - loss: 2.4982e-04 - accuracy: 1.0000\n",
            "Epoch 18/70\n",
            "6/6 [==============================] - 1s 163ms/step - loss: 3.0049e-04 - accuracy: 1.0000\n",
            "Epoch 19/70\n",
            "6/6 [==============================] - 1s 160ms/step - loss: 2.0353e-04 - accuracy: 1.0000\n",
            "Epoch 20/70\n",
            "6/6 [==============================] - 1s 164ms/step - loss: 2.1805e-04 - accuracy: 1.0000\n",
            "Epoch 21/70\n",
            "6/6 [==============================] - 1s 161ms/step - loss: 2.5680e-04 - accuracy: 1.0000\n",
            "Epoch 22/70\n",
            "6/6 [==============================] - 1s 159ms/step - loss: 2.5299e-04 - accuracy: 1.0000\n",
            "Epoch 23/70\n",
            "6/6 [==============================] - 1s 166ms/step - loss: 1.5271e-04 - accuracy: 1.0000\n",
            "Epoch 24/70\n",
            "6/6 [==============================] - 1s 160ms/step - loss: 2.0039e-04 - accuracy: 1.0000\n",
            "Epoch 25/70\n",
            "6/6 [==============================] - 1s 167ms/step - loss: 1.4921e-04 - accuracy: 1.0000\n",
            "Epoch 26/70\n",
            "6/6 [==============================] - 1s 162ms/step - loss: 1.3955e-04 - accuracy: 1.0000\n",
            "Epoch 27/70\n",
            "6/6 [==============================] - 1s 164ms/step - loss: 1.3187e-04 - accuracy: 1.0000\n",
            "Epoch 28/70\n",
            "6/6 [==============================] - 1s 171ms/step - loss: 1.1448e-04 - accuracy: 1.0000\n",
            "Epoch 29/70\n",
            "6/6 [==============================] - 1s 162ms/step - loss: 1.1131e-04 - accuracy: 1.0000\n",
            "Epoch 30/70\n",
            "6/6 [==============================] - 1s 162ms/step - loss: 9.8086e-05 - accuracy: 1.0000\n",
            "Epoch 31/70\n",
            "6/6 [==============================] - 1s 157ms/step - loss: 1.0417e-04 - accuracy: 1.0000\n",
            "Epoch 32/70\n",
            "6/6 [==============================] - 1s 166ms/step - loss: 1.1936e-04 - accuracy: 1.0000\n",
            "Epoch 33/70\n",
            "6/6 [==============================] - 1s 167ms/step - loss: 9.9576e-05 - accuracy: 1.0000\n",
            "Epoch 34/70\n",
            "6/6 [==============================] - 1s 165ms/step - loss: 8.5015e-05 - accuracy: 1.0000\n",
            "Epoch 35/70\n",
            "6/6 [==============================] - 1s 164ms/step - loss: 1.6115e-04 - accuracy: 1.0000\n",
            "Epoch 36/70\n",
            "6/6 [==============================] - 1s 163ms/step - loss: 6.7920e-05 - accuracy: 1.0000\n",
            "Epoch 37/70\n",
            "6/6 [==============================] - 1s 163ms/step - loss: 6.5992e-05 - accuracy: 1.0000\n",
            "Epoch 38/70\n",
            "6/6 [==============================] - 1s 168ms/step - loss: 1.2058e-04 - accuracy: 1.0000\n",
            "Epoch 39/70\n",
            "6/6 [==============================] - 1s 164ms/step - loss: 9.6568e-05 - accuracy: 1.0000\n",
            "Epoch 40/70\n",
            "6/6 [==============================] - 1s 164ms/step - loss: 6.2035e-05 - accuracy: 1.0000\n",
            "Epoch 41/70\n",
            "6/6 [==============================] - 1s 162ms/step - loss: 5.7970e-05 - accuracy: 1.0000\n",
            "Epoch 42/70\n",
            "6/6 [==============================] - 1s 164ms/step - loss: 5.2854e-05 - accuracy: 1.0000\n",
            "Epoch 43/70\n",
            "6/6 [==============================] - 1s 170ms/step - loss: 7.0164e-05 - accuracy: 1.0000\n",
            "Epoch 44/70\n",
            "6/6 [==============================] - 1s 162ms/step - loss: 5.6581e-05 - accuracy: 1.0000\n",
            "Epoch 45/70\n",
            "6/6 [==============================] - 1s 160ms/step - loss: 5.7978e-05 - accuracy: 1.0000\n",
            "Epoch 46/70\n",
            "6/6 [==============================] - 1s 166ms/step - loss: 6.1349e-05 - accuracy: 1.0000\n",
            "Epoch 47/70\n",
            "6/6 [==============================] - 1s 164ms/step - loss: 4.8622e-05 - accuracy: 1.0000\n",
            "Epoch 48/70\n",
            "6/6 [==============================] - 1s 161ms/step - loss: 7.4891e-05 - accuracy: 1.0000\n",
            "Epoch 49/70\n",
            "6/6 [==============================] - 1s 164ms/step - loss: 5.3903e-05 - accuracy: 1.0000\n",
            "Epoch 50/70\n",
            "6/6 [==============================] - 1s 167ms/step - loss: 5.6168e-05 - accuracy: 1.0000\n",
            "Epoch 51/70\n",
            "6/6 [==============================] - 1s 163ms/step - loss: 4.2321e-05 - accuracy: 1.0000\n",
            "Epoch 52/70\n",
            "6/6 [==============================] - 1s 160ms/step - loss: 4.7771e-05 - accuracy: 1.0000\n",
            "Epoch 53/70\n",
            "6/6 [==============================] - 1s 165ms/step - loss: 4.9189e-05 - accuracy: 1.0000\n",
            "Epoch 54/70\n",
            "6/6 [==============================] - 1s 160ms/step - loss: 4.8108e-05 - accuracy: 1.0000\n",
            "Epoch 55/70\n",
            "6/6 [==============================] - 1s 158ms/step - loss: 4.6388e-05 - accuracy: 1.0000\n",
            "Epoch 56/70\n",
            "6/6 [==============================] - 1s 167ms/step - loss: 3.3056e-05 - accuracy: 1.0000\n",
            "Epoch 57/70\n",
            "6/6 [==============================] - 1s 161ms/step - loss: 4.5348e-05 - accuracy: 1.0000\n",
            "Epoch 58/70\n",
            "6/6 [==============================] - 1s 167ms/step - loss: 3.7097e-05 - accuracy: 1.0000\n",
            "Epoch 59/70\n",
            "6/6 [==============================] - 1s 166ms/step - loss: 3.6263e-05 - accuracy: 1.0000\n",
            "Epoch 60/70\n",
            "6/6 [==============================] - 1s 157ms/step - loss: 5.4808e-05 - accuracy: 1.0000\n",
            "Epoch 61/70\n",
            "6/6 [==============================] - 1s 161ms/step - loss: 9.3623e-05 - accuracy: 1.0000\n",
            "Epoch 62/70\n",
            "6/6 [==============================] - 1s 169ms/step - loss: 3.4455e-05 - accuracy: 1.0000\n",
            "Epoch 63/70\n",
            "6/6 [==============================] - 1s 163ms/step - loss: 3.7952e-05 - accuracy: 1.0000\n",
            "Epoch 64/70\n",
            "6/6 [==============================] - 1s 162ms/step - loss: 3.0377e-05 - accuracy: 1.0000\n",
            "Epoch 65/70\n",
            "6/6 [==============================] - 1s 161ms/step - loss: 9.0118e-05 - accuracy: 1.0000\n",
            "Epoch 66/70\n",
            "6/6 [==============================] - 1s 166ms/step - loss: 3.0133e-05 - accuracy: 1.0000\n",
            "Epoch 67/70\n",
            "6/6 [==============================] - 1s 161ms/step - loss: 2.5125e-05 - accuracy: 1.0000\n",
            "Epoch 68/70\n",
            "6/6 [==============================] - 1s 160ms/step - loss: 2.8290e-05 - accuracy: 1.0000\n",
            "Epoch 69/70\n",
            "6/6 [==============================] - 1s 160ms/step - loss: 3.5992e-05 - accuracy: 1.0000\n",
            "Epoch 70/70\n",
            "6/6 [==============================] - 1s 163ms/step - loss: 2.9957e-05 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f2cbc5f6d40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 38ms/step\n",
            "[1, 1, 8, 8, 30, 2, 2, 7, 7, 21, 19, 19, 43, 16, 30, 11, 11, 13, 13, 14, 14, 25, 25, 21, 21, 28, 28, 44, 22, 30, 30, 27, 27, 29, 29, 32, 32, 40, 40, 33, 33, 39, 39, 15, 39, 38, 38, 35, 35, 36, 36, 45, 45, 43, 43, 44, 44, 42, 42, 49, 49, 47, 47, 41, 41, 50, 50]\n",
            "[1, 1, 8, 8, 9, 2, 2, 7, 7, 5, 19, 19, 16, 16, 20, 11, 11, 13, 13, 14, 14, 25, 25, 21, 21, 28, 28, 22, 22, 30, 30, 27, 27, 29, 29, 32, 32, 40, 40, 33, 33, 39, 39, 31, 31, 38, 38, 35, 35, 36, 36, 45, 45, 43, 43, 44, 44, 42, 42, 49, 49, 47, 47, 41, 41, 50, 50]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00         2\n",
            "           2       1.00      1.00      1.00         2\n",
            "           5       0.00      0.00      0.00         1\n",
            "           7       1.00      1.00      1.00         2\n",
            "           8       1.00      1.00      1.00         2\n",
            "           9       0.00      0.00      0.00         1\n",
            "          11       1.00      1.00      1.00         2\n",
            "          13       1.00      1.00      1.00         2\n",
            "          14       1.00      1.00      1.00         2\n",
            "          15       0.00      0.00      0.00         0\n",
            "          16       1.00      0.50      0.67         2\n",
            "          19       1.00      1.00      1.00         2\n",
            "          20       0.00      0.00      0.00         1\n",
            "          21       0.67      1.00      0.80         2\n",
            "          22       1.00      0.50      0.67         2\n",
            "          25       1.00      1.00      1.00         2\n",
            "          27       1.00      1.00      1.00         2\n",
            "          28       1.00      1.00      1.00         2\n",
            "          29       1.00      1.00      1.00         2\n",
            "          30       0.50      1.00      0.67         2\n",
            "          31       0.00      0.00      0.00         2\n",
            "          32       1.00      1.00      1.00         2\n",
            "          33       1.00      1.00      1.00         2\n",
            "          35       1.00      1.00      1.00         2\n",
            "          36       1.00      1.00      1.00         2\n",
            "          38       1.00      1.00      1.00         2\n",
            "          39       0.67      1.00      0.80         2\n",
            "          40       1.00      1.00      1.00         2\n",
            "          41       1.00      1.00      1.00         2\n",
            "          42       1.00      1.00      1.00         2\n",
            "          43       0.67      1.00      0.80         2\n",
            "          44       0.67      1.00      0.80         2\n",
            "          45       1.00      1.00      1.00         2\n",
            "          47       1.00      1.00      1.00         2\n",
            "          49       1.00      1.00      1.00         2\n",
            "          50       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           0.90        67\n",
            "   macro avg       0.81      0.83      0.81        67\n",
            "weighted avg       0.87      0.90      0.87        67\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}